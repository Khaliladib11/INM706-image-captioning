{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96294b6-c1a2-4b47-803d-ff763ec55500",
   "metadata": {},
   "source": [
    "# Build vocabulary for all tests\n",
    "\n",
    "We have problems with our main code because the vocab is built on the fly. \n",
    "\n",
    "If we use the full train2017 file to initiate COCO object, then we use the first 5 captions of each image to build our vocab.\n",
    "\n",
    "If we use subset of train2017 file to initiate COCO object, then we use first 5 captoins of just the subset of images, and so have a smaller vocab.\n",
    "\n",
    "We want to set up the vocab independent of the size and selection of train / val datasets.\n",
    "\n",
    "Here we can build a vocab and then save as json files which we can load into our model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7fcad6-601a-4a1e-83e7-8d86ed1eed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocabulary import Vocabulary\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86939a97-b866-4e94-89c5-7eab59afdcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 591753 captions in the data set\n"
     ]
    }
   ],
   "source": [
    "# for Vocabulary object:\n",
    "FREQ_THRESHOLD = 2\n",
    "SEQUENCE_LENGTH = 60\n",
    "\n",
    "# choose captions file to build vocab. Default is that we use the full training dataset\n",
    "CAPTIONS_FILE = 'captions_train2017.json'\n",
    "# option to set max captions per image when building vocab\n",
    "anns_path = Path('Datasets/coco/annotations/')\n",
    "vocab_path = Path('vocabulary/')\n",
    "\n",
    "with open(anns_path/CAPTIONS_FILE, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "print(f\"There are {len(annotations['annotations'])} captions in the data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57946e9c-0723-4738-8883-e24fc18ed222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With FREQ_THRESHOLD = 6, vocab size is 16232\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary(FREQ_THRESHOLD, SEQUENCE_LENGTH)\n",
    "captions = []\n",
    "word_counts = [0] * 60\n",
    "for d in annotations['annotations']:\n",
    "    captions.append(d['caption'])\n",
    "    if len(captions[-1].split()) >= 60:\n",
    "        print(captions[-1])\n",
    "    else:\n",
    "        word_counts[len(captions[-1].split())] += 1\n",
    "vocab.build_vocabulary(captions)\n",
    "\n",
    "print(\"With FREQ_THRESHOLD = {}, vocab size is {}\"\n",
    "      .format(freq_threshold, len(vocab.idx_to_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bc694f3-a20d-4bd6-ac29-34835a0f56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.bar(x = list(range(1, 30+1)), height = word_counts[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d1aa5e6-4d4c-4c31-9952-61bed3c39b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocab_path/'idx_to_string.json', 'w') as f:\n",
    "    json.dump(vocab.idx_to_string, f)\n",
    "with open(vocab_path/'string_to_index.json', 'w') as f:\n",
    "    json.dump(vocab.string_to_index, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c31c40-f217-4a05-9389-ae0ee0d40cb0",
   "metadata": {},
   "source": [
    "### How many captions do the images have anyway?\n",
    "\n",
    "Almost all have 5. A few have 6 or 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ad0ed0-10a4-41b7-a8c6-22ea91e7277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 117972, 6: 312, 7: 3})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "im_ids = []\n",
    "for d in annotations['annotations']:\n",
    "    im_ids.append(d['image_id'])\n",
    "capt_counts = Counter(im_ids)\n",
    "capt_counts = Counter(list(capt_counts.values()))\n",
    "capt_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20e4b4-81b0-408d-b43f-b8ccb894207d",
   "metadata": {},
   "source": [
    "### What is the size of vocab for different Freq thresholds?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbadd9a0-33c5-4e9f-a254-5959fa94795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With FREQ_THRESHOLD = 1, vocab size is 26852\n",
      "With FREQ_THRESHOLD = 2, vocab size is 16232\n",
      "With FREQ_THRESHOLD = 3, vocab size is 13139\n",
      "With FREQ_THRESHOLD = 4, vocab size is 11360\n",
      "With FREQ_THRESHOLD = 5, vocab size is 10192\n",
      "With FREQ_THRESHOLD = 6, vocab size is 9338\n"
     ]
    }
   ],
   "source": [
    "for freq_threshold in range(1,7):\n",
    "    vocab = Vocabulary(freq_threshold, SEQUENCE_LENGTH)\n",
    "    captions = []\n",
    "    for d in annotations['annotations']:\n",
    "        captions.append(d['caption'])\n",
    "    vocab.build_vocabulary(captions)\n",
    "    print(\"With FREQ_THRESHOLD = {}, vocab size is {}\"\n",
    "          .format(freq_threshold, len(vocab.idx_to_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f0f42-0852-49c4-add6-ad6a98bdb84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
