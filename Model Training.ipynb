{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb673dc",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57e85",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ba6a74-1033-44ad-ac91-930843f720db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import Encoder, Decoder\n",
    "\n",
    "from pathlib import Path\n",
    "from DatasetInterface import MSCOCOInterface\n",
    "from utils import train, save_model, load_model, plot_loss\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "###### run code below if nltk hasn't been set up in clound instance yet\n",
    "# !python -m nltk.downloader -d /usr/local/share/nltk_data all\n",
    "\n",
    "###### run code below to save pre-trained weights if needed\n",
    "# !wget https://download.pytorch.org/models/resnet152-394f9c45.pth\n",
    "# !mv resnet152-394f9c45.pth resnet152_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaa079",
   "metadata": {},
   "source": [
    "## Load Dataset Interface and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2472cfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# load vocab\\nwith open('vocabulary/idx_to_string.json') as json_file:\\n    idx_to_string_json = json.load(json_file)\\n        \\nidx_to_string = dict()\\nfor key in idx_to_string_json:\\n    idx_to_string[int(key)] = idx_to_string_json[key]\\n    \\nwith open('vocabulary/string_to_index.json') as json_file:\\n    string_to_index = json.load(json_file)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########\n",
    "# paths for Khalil\n",
    "#########\n",
    "# root = Path('Data')\n",
    "\n",
    "#captions_path = root/'annotations'/'captions_train2017.json'\n",
    "\n",
    "# train_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_train.json'\n",
    "# val_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_val.json'\n",
    "# test_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "#########\n",
    "# paths for Alex\n",
    "#########\n",
    "\n",
    "root = Path('Datasets/coco')\n",
    "imgs_path = root/'images'/'train2017'\n",
    "imgs_path_test = root/'images'/'val2017'\n",
    "\n",
    "train_captions_path = root/'annotations'/'sports_captions_train.json'\n",
    "val_captions_path = root/'annotations'/'sports_captions_val.json'\n",
    "test_captions_path = root/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "\"\"\"\n",
    "# load vocab\n",
    "with open('vocabulary/idx_to_string.json') as json_file:\n",
    "    idx_to_string_json = json.load(json_file)\n",
    "        \n",
    "idx_to_string = dict()\n",
    "for key in idx_to_string_json:\n",
    "    idx_to_string[int(key)] = idx_to_string_json[key]\n",
    "    \n",
    "with open('vocabulary/string_to_index.json') as json_file:\n",
    "    string_to_index = json.load(json_file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab72e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to boost the performence of CUDA use:\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8143132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interface_params = {\n",
    "    'imgs_path': imgs_path,\n",
    "    'captions_path': train_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'mode': 'train',\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "    \"seed\": 706\n",
    "}\n",
    "\n",
    "val_interface_params = {\n",
    "    'imgs_path': imgs_path,\n",
    "    'captions_path': val_captions_path,\n",
    "    'freq_threshold': 6,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'mode': 'validation',\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "    \"seed\": 706\n",
    "}\n",
    "\n",
    "# Training Interface\n",
    "coco_interface_train = MSCOCOInterface(**train_interface_params)\n",
    "\n",
    "# Validation Interface\n",
    "coco_interface_val = MSCOCOInterface(**val_interface_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38c73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of training image: 500, Lenght of Validation image: 100 Lenght of Testing image: 4939\n",
      "Lenght of vocabulary: 619\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training image: {}, Length of Validation image: {}\"\\\n",
    "      .format(len(coco_interface_train), len(coco_interface_val)))\n",
    "\n",
    "print(f\"Length of vocabulary: {len(coco_interface_train.idx_to_string)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8237cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = data.DataLoader(coco_interface_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(coco_interface_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a85bb9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e041f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512\n",
    "hidden_size = 512\n",
    "vocab_size = len(coco_interface_train.idx_to_string)\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52f24c",
   "metadata": {},
   "source": [
    "## Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fc0b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################READY########################################\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embed_size=embed_size, pretrained=False, model_weight_path=\"./model/resnet152_model.pth\")\n",
    "decoder = Decoder(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers)\n",
    "print(\"########################################READY########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f6a4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is a cross entropy loss and ignore the index of <PAD> since it doesn't make any difference\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=coco_interface_train.string_to_index[\"<PAD>\"])\n",
    "\n",
    "# combine the parameters of decoder and encoder\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "opt_pars = {'lr':1e-3, 'weight_decay':1e-3, 'betas':(0.9, 0.999), 'eps':1e-08}\n",
    "optimizer = optim.Adam(params, **opt_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dff8a",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0   4.385537147521973\n",
      "Training:  100   2.824275255203247\n",
      "Training:  200   4.237329483032227\n",
      "Training:  300   4.2739362716674805\n",
      "Training:  400   3.1215097904205322\n",
      "Validation:  0   3.4859657287597656\n",
      "Epoch: 0. Training Loss = 3.4319, Training Perplexity: 30.9363. Validation Loss: 4.3009, Validation Perplexity: 73.7627. Time: 0.593844\n",
      "Training:  0   3.7339859008789062\n",
      "Training:  100   4.200594425201416\n",
      "Training:  200   3.744450092315674\n",
      "Training:  300   3.726269483566284\n",
      "Training:  400   3.8239715099334717\n",
      "Validation:  0   3.493844985961914\n",
      "Epoch: 1. Training Loss = 3.3969, Training Perplexity: 29.8704. Validation Loss: 4.3056, Validation Perplexity: 74.1118. Time: 1.006393\n",
      "Training:  0   3.647059440612793\n",
      "Training:  100   3.0379064083099365\n",
      "Training:  200   2.3731160163879395\n",
      "Training:  300   3.128211259841919\n",
      "Training:  400   2.9506795406341553\n",
      "Validation:  0   3.4830162525177\n",
      "Epoch: 2. Training Loss = 3.3635, Training Perplexity: 28.8893. Validation Loss: 4.3214, Validation Perplexity: 75.2946. Time: 1.419526\n",
      "Training:  0   3.3759496212005615\n",
      "Training:  100   3.136727809906006\n",
      "Training:  200   3.489413022994995\n",
      "Training:  300   2.116215944290161\n",
      "Training:  400   3.9824142456054688\n",
      "Validation:  0   3.471137285232544\n",
      "Epoch: 3. Training Loss = 3.3316, Training Perplexity: 27.9845. Validation Loss: 4.3313, Validation Perplexity: 76.0433. Time: 1.832341\n",
      "Training:  0   3.3340795040130615\n",
      "Training:  100   2.0259642601013184\n",
      "Training:  200   3.963111639022827\n",
      "Training:  300   3.768460988998413\n",
      "Training:  400   4.201425552368164\n",
      "Validation:  0   3.481130361557007\n"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'encoder': encoder,\n",
    "    'decoder': decoder,\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'total_epoch': 10,\n",
    "    'checkpoint_path': './model/image_captioning_model_v0.pth'\n",
    "}\n",
    "\n",
    "training_loss, validation_loss = train(**train_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c953de0-bd13-47b9-b7b5-dead76bbcae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dec22-ef01-41d2-bfcc-a1383e803bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}