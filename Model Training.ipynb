{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb673dc",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57e85",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e1abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import Encoder, Decoder\n",
    "\n",
    "from pathlib import Path\n",
    "from DatasetInterface import MSCOCOInterface\n",
    "import json\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaa079",
   "metadata": {},
   "source": [
    "## Load Dataset Interface and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472cfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# load vocab\\nwith open('vocabulary/idx_to_string.json') as json_file:\\n    idx_to_string_json = json.load(json_file)\\n        \\nidx_to_string = dict()\\nfor key in idx_to_string_json:\\n    idx_to_string[int(key)] = idx_to_string_json[key]\\n    \\nwith open('vocabulary/string_to_index.json') as json_file:\\n    string_to_index = json.load(json_file)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path('Data')\n",
    "#imgs_path = root/'images'/'train2017'\n",
    "train_imgs_path = root/'train2017'\n",
    "test_imgs_path = root/'val2017'\n",
    "#captions_path = root/'annotations'/'captions_train2017.json'\n",
    "train_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_train.json'\n",
    "val_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_val.json'\n",
    "test_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "\"\"\"\n",
    "# load vocab\n",
    "with open('vocabulary/idx_to_string.json') as json_file:\n",
    "    idx_to_string_json = json.load(json_file)\n",
    "        \n",
    "idx_to_string = dict()\n",
    "for key in idx_to_string_json:\n",
    "    idx_to_string[int(key)] = idx_to_string_json[key]\n",
    "    \n",
    "with open('vocabulary/string_to_index.json') as json_file:\n",
    "    string_to_index = json.load(json_file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab72e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to boost the performence of CUDA use:\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8143132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interface_params = {\n",
    "    'imgs_path': train_imgs_path,\n",
    "    'captions_path': train_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"train\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "val_interface_params = {\n",
    "    'imgs_path': train_imgs_path,\n",
    "    'captions_path': val_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"validation\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "test_interface_params = {\n",
    "    'imgs_path': test_imgs_path,\n",
    "    'captions_path': test_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"test\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "\n",
    "# Training Interface\n",
    "coco_interface_train = MSCOCOInterface(**train_interface_params)\n",
    "\n",
    "# Validation Interface\n",
    "coco_interface_val = MSCOCOInterface(**val_interface_params)\n",
    "\n",
    "# Testing Interface\n",
    "coco_interface_test = MSCOCOInterface(**test_interface_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38c73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of training image: 16252, Lenght of Validation image: 6966 Lenght of Testing image: 938\n",
      "Lenght of vocabulary: 2688\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of training image: {}, Lenght of Validation image: {} Lenght of Testing image: {}\"\\\n",
    "      .format(len(coco_interface_train), len(coco_interface_val), len(coco_interface_test)))\n",
    "\n",
    "print(f\"Lenght of vocabulary: {len(coco_interface_train.idx_to_string)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8237cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = data.DataLoader(coco_interface_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(coco_interface_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = data.DataLoader(coco_interface_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a85bb9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e041f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512\n",
    "hidden_size = 512\n",
    "vocab_size = len(coco_interface_train.idx_to_string)\n",
    "num_layers = 1\n",
    "total_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52f24c",
   "metadata": {},
   "source": [
    "## Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc0b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################READY########################################\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embed_size=embed_size, pretrained=False, model_weight_path=\"./model/resnet152_model.pth\")\n",
    "decoder = Decoder(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers)\n",
    "print(\"########################################READY########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6a4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is a cross entropy loss and ignore the index of <PAD> since it doesn't make any difference\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=coco_interface_train.string_to_index[\"<PAD>\"])\n",
    "\n",
    "# combine the paramters of decoder and ecnoder\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "opt_pars = {'lr':1e-5, 'weight_decay':1e-3, 'betas':(0.9, 0.999), 'eps':1e-08}\n",
    "optimizer = optim.Adam(params, **opt_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dff8a",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c8e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, encoder, decoder, training_loss, validation_loss, checkpoint_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'training_loss': training_loss,\n",
    "        'validation_loss': validation_loss\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_model(encoder, decoder, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    training_loss = checkpoint['training_loss']\n",
    "    validation_loss = checkpoint['validation_loss']\n",
    "    \n",
    "    return encoder, decoder, training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de69f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, training_loss, validation_loss = load_model(encoder, decoder, './model/image_captioning_model_v0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67994682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, criterion, optimizer, train_loader, val_loader, total_epoch, checkpoint_path):\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(total_epoch):\n",
    "        train_epoch_loss = 0\n",
    "        val_epoch_loss = 0\n",
    "        \n",
    "        \n",
    "        # Training phase\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        for id, batch in enumerate(train_loader):\n",
    "            idx, images, captions = batch\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "            \n",
    "            # Zero the gradients.\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            \n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions)\n",
    "            \n",
    "            loss = criterion(outputs.view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_epoch_loss += loss.item()\n",
    "            if id % 100 == 0:\n",
    "                print('Training: ', id, ' ', loss.item())\n",
    "                \n",
    "        train_epoch_loss /= len(train_loader)\n",
    "        training_loss.append(train_epoch_loss)\n",
    "        \n",
    "        # validation phase\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for id, batch in enumerate(val_loader):\n",
    "            idx, images, captions = batch\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "            val_epoch_loss += loss.item()\n",
    "            if id % 100 == 0:\n",
    "                print('Validation: ', id, ' ', loss.item())\n",
    "            \n",
    "        val_epoch_loss /= len(val_loader)\n",
    "        validation_loss.append(val_epoch_loss)\n",
    "    \n",
    "    epoch_time = (time.time() - start_time) /60**1\n",
    "    \n",
    "    save_model(epoch, encoder, decoder, optimizer, training_loss, validation_loss, checkpoint_path)\n",
    "    \n",
    "    print(\"Epoch: {1:d}. Training Loss = {1:.4f}, Training Perplexity: {2:.4f}. Validation Loss: {3:.4f}, Validation Perplexity: {4:.4f}. Time: {5:f}\" \\\n",
    "          .format(epoch, train_epoch_loss, np.exp(train_epoch_loss), val_epoch_loss, np.exp(val_epoch_loss), epoch_time))\n",
    "    \n",
    "    return training_loss, validation_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a0559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0   5.7463603019714355\n",
      "Training:  100   4.77365255355835\n",
      "Training:  200   2.5623116493225098\n",
      "Training:  300   3.593135118484497\n",
      "Training:  400   3.482023000717163\n",
      "Training:  500   3.6291959285736084\n",
      "Training:  600   3.4522058963775635\n",
      "Training:  700   4.048513889312744\n",
      "Training:  800   4.016190052032471\n",
      "Training:  900   3.854299783706665\n",
      "Training:  1000   4.702203750610352\n",
      "Training:  1100   4.716959476470947\n",
      "Training:  1200   5.448296546936035\n",
      "Training:  1300   3.0563738346099854\n",
      "Training:  1400   4.283986568450928\n",
      "Training:  1500   5.271600723266602\n",
      "Training:  1600   4.686922073364258\n",
      "Training:  1700   4.246876239776611\n",
      "Training:  1800   5.75971794128418\n",
      "Training:  1900   3.0879921913146973\n",
      "Training:  2000   2.7001264095306396\n",
      "Training:  2100   3.2407281398773193\n",
      "Training:  2200   6.608675003051758\n",
      "Training:  2300   3.7038471698760986\n",
      "Training:  2400   3.2610924243927\n",
      "Training:  2500   3.7188451290130615\n",
      "Training:  2600   4.580766677856445\n",
      "Training:  2700   4.312746524810791\n",
      "Training:  2800   5.657764434814453\n",
      "Training:  2900   3.38511323928833\n",
      "Training:  3000   3.4782681465148926\n",
      "Training:  3100   5.40718412399292\n",
      "Training:  3200   4.260458469390869\n",
      "Training:  3300   6.249039173126221\n",
      "Training:  3400   3.576355218887329\n",
      "Training:  3500   4.57061243057251\n",
      "Training:  3600   6.815774440765381\n",
      "Training:  3700   2.892407178878784\n",
      "Training:  3800   5.465662956237793\n",
      "Training:  3900   4.654025554656982\n",
      "Training:  4000   6.3435587882995605\n",
      "Training:  4100   5.152500629425049\n",
      "Training:  4200   5.107159614562988\n",
      "Training:  4300   3.33587646484375\n",
      "Training:  4400   4.180241584777832\n",
      "Training:  4500   5.251219749450684\n",
      "Training:  4600   3.8154654502868652\n",
      "Training:  4700   4.954920768737793\n",
      "Training:  4800   4.3660149574279785\n",
      "Training:  4900   6.352502346038818\n",
      "Training:  5000   4.363399028778076\n",
      "Training:  5100   4.204409599304199\n",
      "Training:  5200   4.52170467376709\n",
      "Training:  5300   5.136984348297119\n",
      "Training:  5400   5.623263835906982\n",
      "Training:  5500   3.2745201587677\n",
      "Training:  5600   4.91286039352417\n",
      "Training:  5700   2.8779590129852295\n",
      "Training:  5800   2.473320245742798\n",
      "Training:  5900   4.720983028411865\n",
      "Training:  6000   4.29251766204834\n",
      "Training:  6100   3.520846128463745\n",
      "Training:  6200   4.147965431213379\n",
      "Training:  6300   4.477389812469482\n",
      "Training:  6400   3.223912477493286\n",
      "Training:  6500   4.017585277557373\n",
      "Training:  6600   3.743910312652588\n",
      "Training:  6700   7.1549391746521\n",
      "Training:  6800   3.3115532398223877\n",
      "Training:  6900   5.561359405517578\n",
      "Training:  7000   4.458427429199219\n",
      "Training:  7100   6.570061206817627\n",
      "Training:  7200   3.591573476791382\n",
      "Training:  7300   3.2766106128692627\n",
      "Training:  7400   3.4299957752227783\n",
      "Training:  7500   3.8862757682800293\n",
      "Training:  7600   3.648519277572632\n",
      "Training:  7700   4.277373790740967\n",
      "Training:  7800   4.337414741516113\n",
      "Training:  7900   5.108513832092285\n",
      "Training:  8000   6.773986339569092\n",
      "Training:  8100   2.7916433811187744\n",
      "Training:  8200   3.922203302383423\n",
      "Training:  8300   2.843940019607544\n",
      "Training:  8400   5.56692361831665\n",
      "Training:  8500   2.4637577533721924\n",
      "Training:  8600   5.919677734375\n",
      "Training:  8700   2.8816847801208496\n",
      "Training:  8800   4.933226108551025\n",
      "Training:  8900   2.691451072692871\n",
      "Training:  9000   3.2631075382232666\n",
      "Training:  9100   4.656330108642578\n",
      "Training:  9200   5.039398193359375\n",
      "Training:  9300   3.820455551147461\n",
      "Training:  9400   4.635587215423584\n",
      "Training:  9500   5.222935199737549\n",
      "Training:  9600   3.7277345657348633\n",
      "Training:  9700   4.329973220825195\n",
      "Training:  9800   4.343948841094971\n",
      "Training:  9900   4.593861103057861\n",
      "Training:  10000   3.6658427715301514\n",
      "Training:  10100   5.501926422119141\n",
      "Training:  10200   4.182794570922852\n",
      "Training:  10300   4.195269584655762\n",
      "Training:  10400   4.884477615356445\n",
      "Training:  10500   3.7630786895751953\n",
      "Training:  10600   4.93312931060791\n",
      "Training:  10700   2.4109413623809814\n",
      "Training:  10800   4.879044532775879\n",
      "Training:  10900   6.589856147766113\n",
      "Training:  11000   4.095032691955566\n",
      "Training:  11100   3.370666980743408\n",
      "Training:  11200   5.732478141784668\n",
      "Training:  11300   5.579156875610352\n",
      "Training:  11400   3.27913498878479\n",
      "Training:  11500   3.898397922515869\n",
      "Training:  11600   5.23354959487915\n",
      "Training:  11700   4.066104412078857\n",
      "Training:  11800   3.4771296977996826\n",
      "Training:  11900   3.119109630584717\n",
      "Training:  12000   3.548978090286255\n",
      "Training:  12100   2.599846839904785\n",
      "Training:  12200   4.540980815887451\n",
      "Training:  12300   3.675800085067749\n",
      "Training:  12400   5.748575210571289\n",
      "Training:  12500   5.589536666870117\n",
      "Training:  12600   5.470109939575195\n",
      "Training:  12700   5.767511367797852\n",
      "Training:  12800   4.168055057525635\n",
      "Training:  12900   4.522332668304443\n",
      "Training:  13000   4.252176284790039\n",
      "Training:  13100   3.1071274280548096\n",
      "Training:  13200   4.058341979980469\n",
      "Training:  13300   4.131570339202881\n",
      "Training:  13400   2.762564182281494\n",
      "Training:  13500   4.5552825927734375\n",
      "Training:  13600   2.6324961185455322\n",
      "Training:  13700   3.470900297164917\n",
      "Training:  13800   3.31469988822937\n",
      "Training:  13900   2.889504909515381\n",
      "Training:  14000   5.67609167098999\n",
      "Training:  14100   3.3631999492645264\n",
      "Training:  14200   3.0555293560028076\n",
      "Training:  14300   4.723967552185059\n",
      "Training:  14400   3.8424339294433594\n",
      "Training:  14500   4.567738056182861\n",
      "Training:  14600   4.947824954986572\n",
      "Training:  14700   3.928239583969116\n",
      "Training:  14800   4.617269992828369\n",
      "Training:  14900   5.022529125213623\n",
      "Validation:  0   5.301650047302246\n",
      "Validation:  100   4.324747085571289\n",
      "Validation:  200   4.723311901092529\n",
      "Validation:  300   4.55855655670166\n",
      "Validation:  400   4.7485270500183105\n",
      "Validation:  500   4.062100887298584\n",
      "Validation:  600   4.97287654876709\n",
      "Validation:  700   4.334043979644775\n",
      "Validation:  800   3.238947868347168\n",
      "Validation:  900   2.875049352645874\n",
      "Validation:  1000   3.987992763519287\n",
      "Validation:  1100   2.828558921813965\n",
      "Validation:  1200   3.527397871017456\n",
      "Validation:  1300   6.316865921020508\n",
      "Validation:  1400   4.372751235961914\n",
      "Validation:  1500   5.452448844909668\n",
      "Validation:  1600   3.198608636856079\n",
      "Validation:  1700   4.677599906921387\n",
      "Validation:  1800   4.22340202331543\n",
      "Validation:  1900   4.253638744354248\n",
      "Validation:  2000   2.573751926422119\n",
      "Validation:  2100   3.963319778442383\n",
      "Validation:  2200   4.647735118865967\n",
      "Validation:  2300   3.988435745239258\n",
      "Validation:  2400   4.431511402130127\n",
      "Validation:  2500   4.811970233917236\n",
      "Validation:  2600   2.8935816287994385\n",
      "Validation:  2700   3.7534358501434326\n",
      "Validation:  2800   5.842627048492432\n",
      "Validation:  2900   2.5901050567626953\n",
      "Validation:  3000   4.340949058532715\n",
      "Validation:  3100   6.070252895355225\n",
      "Validation:  3200   4.083333969116211\n",
      "Validation:  3300   6.2404465675354\n",
      "Validation:  3400   2.787747621536255\n",
      "Validation:  3500   6.58827543258667\n",
      "Validation:  3600   5.729103088378906\n",
      "Validation:  3700   2.769211530685425\n",
      "Validation:  3800   4.29531717300415\n",
      "Validation:  3900   4.810667037963867\n",
      "Validation:  4000   3.485507011413574\n",
      "Validation:  4100   3.0929408073425293\n",
      "Validation:  4200   4.703486919403076\n",
      "Validation:  4300   2.518488883972168\n",
      "Validation:  4400   4.118027687072754\n",
      "Validation:  4500   5.007998466491699\n",
      "Validation:  4600   4.427916049957275\n",
      "Validation:  4700   3.0733792781829834\n",
      "Validation:  4800   5.747255802154541\n",
      "Validation:  4900   4.4687299728393555\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_model() takes 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17860\\2988353314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17860\\427038176.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(encoder, decoder, criterion, optimizer, train_loader, val_loader, total_epoch, checkpoint_path)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mepoch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     print(\"Epoch: {1:d}. Training Loss = {1:.4f}, Training Perplexity: {2:.4f}. Validation Loss: {3:.4f}, Validation Perplexity: {4:.4f}. Time: {5:f}\" \\\n",
      "\u001b[1;31mTypeError\u001b[0m: save_model() takes 6 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'encoder': encoder,\n",
    "    'decoder': decoder,\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'total_epoch': 1,\n",
    "    'checkpoint_path': './model/image_captioning_model_v0.pth'\n",
    "}\n",
    "\n",
    "training_loss, validation_loss = train(**train_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b472b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
