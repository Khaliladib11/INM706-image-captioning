{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb673dc",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57e85",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ba6a74-1033-44ad-ac91-930843f720db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import Encoder, Decoder\n",
    "\n",
    "from pathlib import Path\n",
    "from DatasetInterface import MSCOCOInterface\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "###### run code below if nltk hasn't been set up in clound instance yet\n",
    "# !python -m nltk.downloader -d /usr/local/share/nltk_data all\n",
    "\n",
    "###### run code below to save pre-trained weights if needed\n",
    "# !wget https://download.pytorch.org/models/resnet152-394f9c45.pth\n",
    "# !mv resnet152-394f9c45.pth resnet152_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaa079",
   "metadata": {},
   "source": [
    "## Load Dataset Interface and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472cfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# load vocab\\nwith open('vocabulary/idx_to_string.json') as json_file:\\n    idx_to_string_json = json.load(json_file)\\n        \\nidx_to_string = dict()\\nfor key in idx_to_string_json:\\n    idx_to_string[int(key)] = idx_to_string_json[key]\\n    \\nwith open('vocabulary/string_to_index.json') as json_file:\\n    string_to_index = json.load(json_file)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########\n",
    "# paths for Khalil\n",
    "#########\n",
    "# root = Path('Data')\n",
    "\n",
    "#captions_path = root/'annotations'/'captions_train2017.json'\n",
    "\n",
    "# train_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_train.json'\n",
    "# val_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_val.json'\n",
    "# test_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "#########\n",
    "# paths for Alex\n",
    "#########\n",
    "\n",
    "root = Path('Datasets/coco')\n",
    "imgs_path = root/'images'/'train2017'\n",
    "imgs_path_test = root/'images'/'val2017'\n",
    "\n",
    "train_captions_path = root/'annotations'/'sports_captions_train.json'\n",
    "val_captions_path = root/'annotations'/'sports_captions_val.json'\n",
    "test_captions_path = root/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "\"\"\"\n",
    "# load vocab\n",
    "with open('vocabulary/idx_to_string.json') as json_file:\n",
    "    idx_to_string_json = json.load(json_file)\n",
    "        \n",
    "idx_to_string = dict()\n",
    "for key in idx_to_string_json:\n",
    "    idx_to_string[int(key)] = idx_to_string_json[key]\n",
    "    \n",
    "with open('vocabulary/string_to_index.json') as json_file:\n",
    "    string_to_index = json.load(json_file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab72e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to boost the performence of CUDA use:\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8143132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interface_params = {\n",
    "    'imgs_path': imgs_path,\n",
    "    'captions_path': train_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"train\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "val_interface_params = {\n",
    "    'imgs_path': imgs_path,\n",
    "    'captions_path': val_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"validation\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "test_interface_params = {\n",
    "    'imgs_path': imgs_path_test,\n",
    "    'captions_path': test_captions_path,\n",
    "    'freq_threshold': 5,\n",
    "    'sequence_length': 20,\n",
    "    'caps_per_img': 1,\n",
    "    'stage': \"test\",\n",
    "    'idx_to_string': None,\n",
    "    'string_to_index': None,\n",
    "}\n",
    "\n",
    "\n",
    "# Training Interface\n",
    "coco_interface_train = MSCOCOInterface(**train_interface_params)\n",
    "\n",
    "# Validation Interface\n",
    "coco_interface_val = MSCOCOInterface(**val_interface_params)\n",
    "\n",
    "# Testing Interface\n",
    "coco_interface_test = MSCOCOInterface(**test_interface_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38c73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of training image: 20199, Lenght of Validation image: 3019 Lenght of Testing image: 938\n",
      "Lenght of vocabulary: 2987\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of training image: {}, Lenght of Validation image: {} Lenght of Testing image: {}\"\\\n",
    "      .format(len(coco_interface_train), len(coco_interface_val), len(coco_interface_test)))\n",
    "\n",
    "print(f\"Lenght of vocabulary: {len(coco_interface_train.idx_to_string)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8237cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = data.DataLoader(coco_interface_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(coco_interface_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = data.DataLoader(coco_interface_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a85bb9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e041f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512\n",
    "hidden_size = 512\n",
    "vocab_size = len(coco_interface_train.idx_to_string)\n",
    "num_layers = 1\n",
    "total_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52f24c",
   "metadata": {},
   "source": [
    "## Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc0b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################READY########################################\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embed_size=embed_size, pretrained=False, model_weight_path=\"./model/resnet152_model.pth\")\n",
    "decoder = Decoder(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers)\n",
    "print(\"########################################READY########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6a4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is a cross entropy loss and ignore the index of <PAD> since it doesn't make any difference\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=coco_interface_train.string_to_index[\"<PAD>\"])\n",
    "\n",
    "# combine the paramters of decoder and ecnoder\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "opt_pars = {'lr':1e-5, 'weight_decay':1e-3, 'betas':(0.9, 0.999), 'eps':1e-08}\n",
    "optimizer = optim.Adam(params, **opt_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dff8a",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c8e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, encoder, decoder, training_loss, validation_loss, checkpoint_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'training_loss': training_loss,\n",
    "        'validation_loss': validation_loss\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_model(encoder, decoder, checkpoint_path):\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    training_loss = checkpoint['training_loss']\n",
    "    validation_loss = checkpoint['validation_loss']\n",
    "\n",
    "    return encoder, decoder, training_loss, validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de69f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/image_captioning_model_v0.pth file does not exist, training startging from scratch\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = './model/image_captioning_model_v0.pth'\n",
    "if Path(CHECKPOINT).exists():\n",
    "    encoder, decoder, training_loss, validation_loss = load_model(encoder, decoder, CHECKPOINTPOINT)\n",
    "else:\n",
    "    print(f'{CHECKPOINT} file does not exist, training startging from scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67994682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, criterion, optimizer, train_loader, val_loader, total_epoch, checkpoint_path):\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(total_epoch):\n",
    "        train_epoch_loss = 0\n",
    "        val_epoch_loss = 0\n",
    "        \n",
    "        \n",
    "        # Training phase\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        for id, batch in enumerate(train_loader):\n",
    "            idx, images, captions = batch\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "            \n",
    "            # Zero the gradients.\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            \n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions)\n",
    "            \n",
    "            loss = criterion(outputs.view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_epoch_loss += loss.item()\n",
    "            if id % 100 == 0:\n",
    "                print('Training: ', id, ' ', loss.item())\n",
    "                \n",
    "        train_epoch_loss /= len(train_loader)\n",
    "        training_loss.append(train_epoch_loss)\n",
    "        \n",
    "        # validation phase\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        for id, batch in enumerate(val_loader):\n",
    "            idx, images, captions = batch\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "            val_epoch_loss += loss.item()\n",
    "            if id % 100 == 0:\n",
    "                print('Validation: ', id, ' ', loss.item())\n",
    "            \n",
    "        val_epoch_loss /= len(val_loader)\n",
    "        validation_loss.append(val_epoch_loss)\n",
    "    \n",
    "    epoch_time = (time.time() - start_time) /60**1\n",
    "    \n",
    "    save_model(epoch, encoder, decoder, training_loss, validation_loss, checkpoint_path)\n",
    "    \n",
    "    print(\"Epoch: {1:d}. Training Loss = {1:.4f}, Training Perplexity: {2:.4f}. Validation Loss: {3:.4f}, Validation Perplexity: {4:.4f}. Time: {5:f}\" \\\n",
    "          .format(epoch, train_epoch_loss, np.exp(train_epoch_loss), val_epoch_loss, np.exp(val_epoch_loss), epoch_time))\n",
    "    \n",
    "    return training_loss, validation_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0   2.050968885421753\n",
      "Training:  100   3.074071168899536\n",
      "Training:  200   2.8299477100372314\n",
      "Training:  300   4.792208194732666\n",
      "Training:  400   2.83084774017334\n",
      "Training:  500   4.372940540313721\n",
      "Training:  600   3.280672311782837\n",
      "Training:  700   5.61635160446167\n",
      "Training:  800   2.8342390060424805\n",
      "Training:  900   2.309440851211548\n",
      "Training:  1000   2.1391849517822266\n",
      "Training:  1100   3.0500712394714355\n",
      "Training:  1200   1.3538862466812134\n",
      "Training:  1300   3.903350591659546\n",
      "Training:  1400   2.4949448108673096\n",
      "Training:  1500   2.226013422012329\n",
      "Training:  1600   2.2248520851135254\n",
      "Training:  1700   3.126995801925659\n",
      "Training:  1800   3.3193271160125732\n",
      "Training:  1900   3.481590509414673\n",
      "Training:  2000   3.1484131813049316\n",
      "Training:  2100   1.9759788513183594\n",
      "Training:  2200   1.512735366821289\n",
      "Training:  2300   1.817917823791504\n",
      "Training:  2400   3.1741931438446045\n",
      "Training:  2500   2.340545654296875\n",
      "Training:  2600   3.086394786834717\n",
      "Training:  2700   3.5453481674194336\n",
      "Training:  2800   3.226271629333496\n",
      "Training:  2900   2.3165969848632812\n",
      "Training:  3000   1.8546563386917114\n",
      "Training:  3100   2.244204521179199\n",
      "Training:  3200   3.094135046005249\n",
      "Training:  3300   1.6897352933883667\n",
      "Training:  3400   2.7577645778656006\n",
      "Training:  3500   1.9222971200942993\n",
      "Training:  3600   1.3954463005065918\n",
      "Training:  3700   3.1628308296203613\n",
      "Training:  3800   1.885376214981079\n",
      "Training:  3900   1.599295973777771\n",
      "Training:  4000   1.7677674293518066\n",
      "Training:  4100   3.0824134349823\n",
      "Training:  4200   3.0974361896514893\n",
      "Training:  4300   3.10906982421875\n",
      "Training:  4400   2.7016210556030273\n",
      "Training:  4500   2.727658271789551\n",
      "Training:  4600   3.67537784576416\n",
      "Training:  4700   1.7074819803237915\n",
      "Training:  4800   4.327521800994873\n",
      "Training:  4900   1.689170479774475\n",
      "Training:  5000   3.1661386489868164\n",
      "Training:  5100   3.8994221687316895\n",
      "Training:  5200   3.0858259201049805\n",
      "Training:  5300   4.618180751800537\n",
      "Training:  5400   2.6798384189605713\n",
      "Training:  5500   1.3602739572525024\n",
      "Training:  5600   2.3144209384918213\n",
      "Training:  5700   4.7979583740234375\n",
      "Training:  5800   3.965193271636963\n",
      "Training:  5900   4.915892601013184\n",
      "Training:  6000   3.9987614154815674\n",
      "Training:  6100   4.655418395996094\n",
      "Training:  6200   1.08790922164917\n",
      "Training:  6300   3.695000171661377\n",
      "Training:  6400   1.1874226331710815\n",
      "Training:  6500   1.4955657720565796\n",
      "Training:  6600   3.284806251525879\n",
      "Training:  6700   2.63183856010437\n",
      "Training:  6800   2.832416534423828\n",
      "Training:  6900   1.1942299604415894\n",
      "Training:  7000   3.3326528072357178\n",
      "Training:  7100   3.9330897331237793\n",
      "Training:  7200   4.266270637512207\n",
      "Training:  7300   3.0784311294555664\n",
      "Training:  7400   1.993799090385437\n",
      "Training:  7500   2.8357105255126953\n",
      "Training:  7600   1.7250499725341797\n",
      "Training:  7700   3.4279255867004395\n",
      "Training:  7800   1.6668072938919067\n",
      "Training:  7900   3.9595978260040283\n",
      "Training:  8000   4.41140079498291\n",
      "Training:  8100   2.8316123485565186\n",
      "Training:  8200   2.4048404693603516\n",
      "Training:  8300   4.317173480987549\n",
      "Training:  8400   5.024020671844482\n",
      "Training:  8500   5.3149333000183105\n",
      "Training:  8600   2.173067808151245\n",
      "Training:  8700   2.594391345977783\n",
      "Training:  8800   1.5476727485656738\n",
      "Training:  8900   2.906898260116577\n",
      "Training:  9000   4.592912197113037\n",
      "Training:  9100   2.2917747497558594\n",
      "Training:  9200   5.196959018707275\n",
      "Training:  9300   3.484866142272949\n",
      "Training:  9400   4.400327682495117\n",
      "Training:  9500   2.0986075401306152\n",
      "Training:  9600   1.623844861984253\n",
      "Training:  9700   3.045734167098999\n",
      "Training:  9800   0.983701765537262\n",
      "Training:  9900   2.617602586746216\n",
      "Training:  10000   4.969951152801514\n",
      "Training:  10100   2.913520097732544\n",
      "Training:  10200   1.9333969354629517\n",
      "Training:  10300   3.4753401279449463\n",
      "Training:  10400   3.7316863536834717\n",
      "Training:  10500   3.026134967803955\n",
      "Training:  10600   2.545989513397217\n",
      "Training:  10700   3.6178033351898193\n",
      "Training:  10800   2.0306482315063477\n",
      "Training:  10900   3.458645820617676\n",
      "Training:  11000   4.368791580200195\n",
      "Training:  11100   2.590515613555908\n",
      "Training:  11200   1.413315773010254\n",
      "Training:  11300   2.6977100372314453\n",
      "Training:  11400   3.1582205295562744\n",
      "Training:  11500   2.150675058364868\n",
      "Training:  11600   3.7050156593322754\n",
      "Training:  11700   1.6409021615982056\n",
      "Training:  11800   2.2580201625823975\n",
      "Training:  11900   3.630401611328125\n",
      "Training:  12000   1.4834481477737427\n",
      "Training:  12100   1.4708720445632935\n",
      "Training:  12200   3.0049073696136475\n",
      "Training:  12300   4.098459720611572\n",
      "Training:  12400   3.813504934310913\n",
      "Training:  12500   4.108842372894287\n",
      "Training:  12600   2.978224039077759\n",
      "Training:  12700   4.778887748718262\n",
      "Training:  12800   3.5379583835601807\n",
      "Training:  12900   3.205660581588745\n",
      "Training:  13000   0.9732483625411987\n",
      "Training:  13100   1.2843621969223022\n",
      "Training:  13200   3.3971946239471436\n",
      "Training:  13300   3.109644651412964\n",
      "Training:  13400   1.551561951637268\n",
      "Training:  13500   3.7935750484466553\n",
      "Training:  13600   3.9881858825683594\n",
      "Training:  13700   4.368785381317139\n",
      "Training:  13800   3.2457547187805176\n",
      "Training:  13900   2.8292388916015625\n",
      "Training:  14000   2.0695345401763916\n",
      "Training:  14100   2.2052454948425293\n",
      "Training:  14200   1.2279905080795288\n",
      "Training:  14300   3.3982441425323486\n",
      "Training:  14400   3.517190933227539\n",
      "Training:  14500   2.3579463958740234\n",
      "Training:  14600   2.9934844970703125\n",
      "Training:  14700   2.5451905727386475\n",
      "Training:  14800   3.53979229927063\n",
      "Training:  14900   3.4732439517974854\n",
      "Training:  15000   3.291810989379883\n",
      "Training:  15100   1.9028769731521606\n",
      "Training:  15200   4.8127827644348145\n",
      "Training:  15300   1.4714967012405396\n",
      "Training:  15400   2.4784393310546875\n",
      "Training:  15500   4.338230133056641\n",
      "Training:  15600   3.624845027923584\n",
      "Training:  15700   4.158932209014893\n",
      "Training:  15800   0.9193090796470642\n",
      "Training:  15900   2.3329429626464844\n",
      "Training:  16000   3.4935898780822754\n",
      "Training:  16100   4.022594928741455\n",
      "Training:  16200   2.8101110458374023\n",
      "Training:  16300   4.333658218383789\n",
      "Training:  16400   3.3373489379882812\n",
      "Training:  16500   3.761315107345581\n",
      "Training:  16600   2.3752033710479736\n",
      "Training:  16700   2.4638378620147705\n",
      "Training:  16800   1.8571947813034058\n",
      "Training:  16900   4.256504535675049\n",
      "Training:  17000   3.9681639671325684\n",
      "Training:  17100   2.5467169284820557\n",
      "Training:  17200   2.2589519023895264\n",
      "Training:  17300   2.9968771934509277\n",
      "Training:  17400   2.759066581726074\n",
      "Training:  17500   2.7081081867218018\n",
      "Training:  17600   5.462621688842773\n",
      "Training:  17700   4.000503063201904\n",
      "Training:  17800   2.5017213821411133\n",
      "Training:  17900   2.9280426502227783\n",
      "Training:  18000   1.3179240226745605\n",
      "Training:  18100   2.364619016647339\n",
      "Training:  18200   2.292543649673462\n",
      "Training:  18300   1.9703738689422607\n",
      "Training:  18400   2.685149669647217\n",
      "Training:  18500   3.651193618774414\n",
      "Training:  18600   2.075611114501953\n",
      "Training:  18700   3.5937201976776123\n",
      "Training:  18800   5.2172980308532715\n",
      "Training:  18900   1.654046654701233\n",
      "Training:  19000   3.4987313747406006\n",
      "Training:  19100   1.9275118112564087\n",
      "Training:  19200   3.426922082901001\n",
      "Training:  19300   3.5725646018981934\n",
      "Training:  19400   3.7060728073120117\n",
      "Training:  19500   3.4029541015625\n",
      "Training:  19600   1.133423924446106\n",
      "Training:  19700   3.5186188220977783\n",
      "Training:  19800   1.2815121412277222\n",
      "Training:  19900   4.440993785858154\n",
      "Training:  20000   4.033543109893799\n"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'encoder': encoder,\n",
    "    'decoder': decoder,\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'total_epoch': 1,\n",
    "    'checkpoint_path': './model/image_captioning_model_v0.pth'\n",
    "}\n",
    "\n",
    "training_loss, validation_loss = train(**train_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8404d-3428-4363-a71e-debe5bfb12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976cee36-4e85-46be-9805-98c43682cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Path.cwd()/'Datasets/coco/images/val2017/'\n",
    "len(sorted(f.glob('**/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd744131-ded2-4256-bf86-5601ded46050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = Path.cwd()/'Datasets/coco/images/train2017/'\n",
    "len(sorted(f2.glob('**/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7d621-c381-4bee-bc46-34f3e3df891b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
