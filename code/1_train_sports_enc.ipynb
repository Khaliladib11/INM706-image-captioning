{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09b4c42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a3db4",
   "metadata": {},
   "source": [
    "All our training is done using 10k / 2k / 2k sized data for train / val / test.\n",
    "\n",
    "This notebook narrows images to only those with sports in them. We then randomly sample these to get 10k / 2k / 2k. This gives us a slightly smaller vocab, but same size dataset. \n",
    "\n",
    "We only train on images containing sports categories. \n",
    "\n",
    "This is an alternative version of sport_v2. It uses different encoder architecture: one final fully connected layer rather than the two layers we use everywhere else. NOTE: WE IMPLEMENTED THIS OUTSIDE OUR USUAL WORK FLOW THAT THE CODE WAS DESIGNED FOR. IT INVOLVED TEMPORARILY CHANGING THE CODE IN THE ENCODER CLASS, AND THIS NOTEBOOK WILL NOT SUCCESSFULLY RUN WITHOUT CHANGING THE ENCODER MODULE.\n",
    "\n",
    "We leave this notebook in for completeness, and because it is a pointer for future code development. We would definitely have the option for a different encoder architecture in future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606af7ca",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccfe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_loader import get_loader\n",
    "from models import Encoder, Decoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from data_prep_utils import *\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff406e5e",
   "metadata": {},
   "source": [
    "## Load train and validation loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd484d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = '../../CW/Data/train2017'\n",
    "#captions_path = '../../CW/Data/annotations_trainval2017/annotations/captions_train2017.json'\n",
    "IMAGE_PATH = '../Datasets/coco/images/train2017'\n",
    "CAPTIONS_PATH = '../Datasets/coco/annotations/' #captions_train2017.json'\n",
    "FREQ_THRESHOLD = 4\n",
    "CAPS_PER_IMAGE = 5\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE = True\n",
    "\n",
    "# root of the name to save or load captions files\n",
    "CAPTIONS_NAME = 'sports_encoder_v2'\n",
    "SUPER_CATEGORIES = ['sports'] # should be list of eligible coco super categories, or None to include all images\n",
    "\n",
    "# for encoder and decoder\n",
    "EMBED_SIZE = 512  # dimension of vocab embedding vector\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 3  # hidden layers in LTSM\n",
    "\n",
    "# training parameters\n",
    "PRINT_EVERY = 100\n",
    "TOTAL_EPOCH = 20\n",
    "CHECKPOINT = '../model/model_sport_encoder_v2' # there is no v1 for sports:\n",
    "# v2 is consistent with previous tests as v2 parameters are shared across data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a247cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 15000 images\n",
      " val dataset has 2000 images\n",
      " test dataset has 938 images\n",
      "There are 75039 captions in the data set\n",
      "With FREQ_THRESHOLD = 4, vocab size is 2921\n"
     ]
    }
   ],
   "source": [
    "# of images or reduce the size of the data\n",
    "# this will write files to 'Datasets/coco/annotations' as \n",
    "#     [save_name]_captions_train.json\n",
    "#     [save_name]_captions_val.json\n",
    "#     [save_name]_captions_test.json\n",
    "\n",
    "prepare_datasets(train_percent = 0.87, super_categories=['sports'],\n",
    "                 max_train=15000, max_val=2000, max_test=2000,\n",
    "                 save_name=CAPTIONS_NAME, random_seed=42)\n",
    "\n",
    "# we explicitly build the vocab here. We use frequency threshold, and we build\n",
    "# vocab from the specified captions file: we're using the training data\n",
    "# we save the vocab to a name consistent with our training captions data so that \n",
    "# we can load a vocab consistent with the specific training run we've used.\n",
    "build_vocab(freq_threshold = FREQ_THRESHOLD, \n",
    "            captions_file=f'{CAPTIONS_NAME}_captions_train.json',\n",
    "            vocab_save_name=CAPTIONS_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d977f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../vocabulary/{CAPTIONS_NAME}word2idx.json', 'r') as f:\n",
    "    word2idx = json.load(f)\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4115c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataloader: 586, Length of testing dataloader: 47\n",
      "Length of vocabulary: 2921\n"
     ]
    }
   ],
   "source": [
    "train_loader_params = {\n",
    "    'images_path': IMAGE_PATH,\n",
    "    'captions_path': CAPTIONS_PATH + f'{CAPTIONS_NAME}_captions_train.json',\n",
    "    'freq_threshold': FREQ_THRESHOLD,\n",
    "    'caps_per_image': 5,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'mode': 'train',\n",
    "    # 'idx2word': None,\n",
    "    'word2idx': word2idx\n",
    "}\n",
    "\n",
    "train_loader, train_dataset = get_loader(**train_loader_params)\n",
    "\n",
    "val_loader_params = {\n",
    "    'images_path': IMAGE_PATH,\n",
    "    'captions_path': CAPTIONS_PATH + f'{CAPTIONS_NAME}_captions_val.json',\n",
    "    'freq_threshold': FREQ_THRESHOLD,\n",
    "    'caps_per_image': 3,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'mode': 'validation',\n",
    "    # 'idx2word': train_dataset.vocab.idx2word,\n",
    "    'word2idx': word2idx\n",
    "}\n",
    "\n",
    "val_loader, val_dataset = get_loader(**val_loader_params)\n",
    "\n",
    "print(f\"Length of training dataloader: {len(train_loader)}, Length of testing dataloader: {len(val_loader)}\")\n",
    "print(f\"Length of vocabulary: {len(train_dataset.vocab.idx2word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde1d50",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593a54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"We are using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b038a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(embed_size=EMBED_SIZE, pretrained=True)\n",
    "decoder = Decoder(embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, num_layers=NUM_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4fc7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is a cross entropy loss and ignore the index of <PAD> since it doesn't make any difference\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.vocab.word2idx[\"<PAD>\"]).cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss(ignore_index=train_dataset.vocab.word2idx[\"<PAD>\"])\n",
    "\n",
    "# combine the parameters of decoder and encoder\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "opt_pars = {'lr':1e-3, 'weight_decay':1e-3, 'betas':(0.9, 0.999), 'eps':1e-08}\n",
    "optimizer = optim.Adam(params, **opt_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceaa922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'save_path': CHECKPOINT,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'embed_size': EMBED_SIZE,\n",
    "    'hidden_size': HIDDEN_SIZE,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'vocab_size': len(train_dataset.vocab.idx2word)\n",
    "}\n",
    "\n",
    "save_params(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fd73a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a62141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/20]          || Step: [0/586]         || Average Training Loss: 7.9808\n",
      "Epoch: [0/20]          || Step: [100/586]       || Average Training Loss: 4.6321\n",
      "Epoch: [0/20]          || Step: [200/586]       || Average Training Loss: 4.1362\n",
      "Epoch: [0/20]          || Step: [300/586]       || Average Training Loss: 3.8262\n",
      "Epoch: [0/20]          || Step: [400/586]       || Average Training Loss: 3.6163\n",
      "Epoch: [0/20]          || Step: [500/586]       || Average Training Loss: 3.4604\n",
      "Epoch: [0/20]          || Step: [0/47]          || Average Validation Loss: 2.9689\n",
      "****************************************************************************************************\n",
      "Epoch: [0/20] || Training Loss = 3.35 || Validation Loss: 2.63 || Time: 23.740939\n",
      "****************************************************************************************************\n",
      "Epoch: [1/20]          || Step: [0/586]         || Average Training Loss: 2.7639\n",
      "Epoch: [1/20]          || Step: [100/586]       || Average Training Loss: 2.6424\n",
      "Epoch: [1/20]          || Step: [200/586]       || Average Training Loss: 2.6165\n",
      "Epoch: [1/20]          || Step: [300/586]       || Average Training Loss: 2.5943\n",
      "Epoch: [1/20]          || Step: [400/586]       || Average Training Loss: 2.5751\n",
      "Epoch: [1/20]          || Step: [500/586]       || Average Training Loss: 2.5581\n",
      "Epoch: [1/20]          || Step: [0/47]          || Average Validation Loss: 2.4301\n",
      "****************************************************************************************************\n",
      "Epoch: [1/20] || Training Loss = 2.55 || Validation Loss: 2.41 || Time: 23.178680\n",
      "****************************************************************************************************\n",
      "Epoch: [2/20]          || Step: [0/586]         || Average Training Loss: 2.3178\n",
      "Epoch: [2/20]          || Step: [100/586]       || Average Training Loss: 2.4538\n",
      "Epoch: [2/20]          || Step: [200/586]       || Average Training Loss: 2.4541\n",
      "Epoch: [2/20]          || Step: [300/586]       || Average Training Loss: 2.4537\n",
      "Epoch: [2/20]          || Step: [400/586]       || Average Training Loss: 2.4524\n",
      "Epoch: [2/20]          || Step: [500/586]       || Average Training Loss: 2.4497\n",
      "Epoch: [2/20]          || Step: [0/47]          || Average Validation Loss: 2.5227\n",
      "****************************************************************************************************\n",
      "Epoch: [2/20] || Training Loss = 2.45 || Validation Loss: 2.38 || Time: 23.360416\n",
      "****************************************************************************************************\n",
      "Epoch: [3/20]          || Step: [0/586]         || Average Training Loss: 2.3738\n",
      "Epoch: [3/20]          || Step: [100/586]       || Average Training Loss: 2.4387\n",
      "Epoch: [3/20]          || Step: [200/586]       || Average Training Loss: 2.4236\n",
      "Epoch: [3/20]          || Step: [300/586]       || Average Training Loss: 2.4210\n",
      "Epoch: [3/20]          || Step: [400/586]       || Average Training Loss: 2.4185\n",
      "Epoch: [3/20]          || Step: [500/586]       || Average Training Loss: 2.4195\n",
      "Epoch: [3/20]          || Step: [0/47]          || Average Validation Loss: 2.3609\n",
      "****************************************************************************************************\n",
      "Epoch: [3/20] || Training Loss = 2.42 || Validation Loss: 2.37 || Time: 23.160737\n",
      "****************************************************************************************************\n",
      "Epoch: [4/20]          || Step: [0/586]         || Average Training Loss: 2.3846\n",
      "Epoch: [4/20]          || Step: [100/586]       || Average Training Loss: 2.3871\n",
      "Epoch: [4/20]          || Step: [200/586]       || Average Training Loss: 2.4049\n",
      "Epoch: [4/20]          || Step: [300/586]       || Average Training Loss: 2.4017\n",
      "Epoch: [4/20]          || Step: [400/586]       || Average Training Loss: 2.4013\n",
      "Epoch: [4/20]          || Step: [500/586]       || Average Training Loss: 2.4022\n",
      "Epoch: [4/20]          || Step: [0/47]          || Average Validation Loss: 2.2574\n",
      "****************************************************************************************************\n",
      "Epoch: [4/20] || Training Loss = 2.40 || Validation Loss: 2.35 || Time: 23.172966\n",
      "****************************************************************************************************\n",
      "Epoch: [5/20]          || Step: [0/586]         || Average Training Loss: 2.4760\n",
      "Epoch: [5/20]          || Step: [100/586]       || Average Training Loss: 2.3817\n",
      "Epoch: [5/20]          || Step: [200/586]       || Average Training Loss: 2.3832\n",
      "Epoch: [5/20]          || Step: [300/586]       || Average Training Loss: 2.3893\n",
      "Epoch: [5/20]          || Step: [400/586]       || Average Training Loss: 2.3884\n",
      "Epoch: [5/20]          || Step: [500/586]       || Average Training Loss: 2.3903\n",
      "Epoch: [5/20]          || Step: [0/47]          || Average Validation Loss: 2.4638\n",
      "****************************************************************************************************\n",
      "Epoch: [5/20] || Training Loss = 2.39 || Validation Loss: 2.35 || Time: 23.011588\n",
      "****************************************************************************************************\n",
      "Epoch: [6/20]          || Step: [0/586]         || Average Training Loss: 2.2546\n",
      "Epoch: [6/20]          || Step: [100/586]       || Average Training Loss: 2.3836\n",
      "Epoch: [6/20]          || Step: [200/586]       || Average Training Loss: 2.3806\n",
      "Epoch: [6/20]          || Step: [300/586]       || Average Training Loss: 2.3801\n",
      "Epoch: [6/20]          || Step: [400/586]       || Average Training Loss: 2.3769\n",
      "Epoch: [6/20]          || Step: [500/586]       || Average Training Loss: 2.3778\n",
      "Epoch: [6/20]          || Step: [0/47]          || Average Validation Loss: 2.3036\n",
      "****************************************************************************************************\n",
      "Epoch: [6/20] || Training Loss = 2.38 || Validation Loss: 2.33 || Time: 23.317351\n",
      "****************************************************************************************************\n",
      "Epoch: [7/20]          || Step: [0/586]         || Average Training Loss: 2.4315\n",
      "Epoch: [7/20]          || Step: [100/586]       || Average Training Loss: 2.3536\n",
      "Epoch: [7/20]          || Step: [200/586]       || Average Training Loss: 2.3600\n",
      "Epoch: [7/20]          || Step: [300/586]       || Average Training Loss: 2.3655\n",
      "Epoch: [7/20]          || Step: [400/586]       || Average Training Loss: 2.3642\n",
      "Epoch: [7/20]          || Step: [500/586]       || Average Training Loss: 2.3651\n",
      "Epoch: [7/20]          || Step: [0/47]          || Average Validation Loss: 2.2989\n",
      "****************************************************************************************************\n",
      "Epoch: [7/20] || Training Loss = 2.37 || Validation Loss: 2.32 || Time: 23.932094\n",
      "****************************************************************************************************\n",
      "Epoch: [8/20]          || Step: [0/586]         || Average Training Loss: 2.4250\n",
      "Epoch: [8/20]          || Step: [100/586]       || Average Training Loss: 2.3616\n",
      "Epoch: [8/20]          || Step: [200/586]       || Average Training Loss: 2.3529\n",
      "Epoch: [8/20]          || Step: [300/586]       || Average Training Loss: 2.3559\n",
      "Epoch: [8/20]          || Step: [400/586]       || Average Training Loss: 2.3600\n",
      "Epoch: [8/20]          || Step: [500/586]       || Average Training Loss: 2.3608\n",
      "Epoch: [8/20]          || Step: [0/47]          || Average Validation Loss: 2.1606\n",
      "****************************************************************************************************\n",
      "Epoch: [8/20] || Training Loss = 2.36 || Validation Loss: 2.33 || Time: 23.500243\n",
      "****************************************************************************************************\n",
      "Epoch: [9/20]          || Step: [0/586]         || Average Training Loss: 2.4414\n",
      "Epoch: [9/20]          || Step: [100/586]       || Average Training Loss: 2.3506\n",
      "Epoch: [9/20]          || Step: [200/586]       || Average Training Loss: 2.3496\n",
      "Epoch: [9/20]          || Step: [300/586]       || Average Training Loss: 2.3485\n",
      "Epoch: [9/20]          || Step: [400/586]       || Average Training Loss: 2.3507\n",
      "Epoch: [9/20]          || Step: [500/586]       || Average Training Loss: 2.3505\n",
      "Epoch: [9/20]          || Step: [0/47]          || Average Validation Loss: 2.3130\n",
      "****************************************************************************************************\n",
      "Epoch: [9/20] || Training Loss = 2.35 || Validation Loss: 2.32 || Time: 23.462669\n",
      "****************************************************************************************************\n",
      "Epoch: [10/20]         || Step: [0/586]         || Average Training Loss: 2.4568\n",
      "Epoch: [10/20]         || Step: [100/586]       || Average Training Loss: 2.3413\n",
      "Epoch: [10/20]         || Step: [200/586]       || Average Training Loss: 2.3453\n",
      "Epoch: [10/20]         || Step: [300/586]       || Average Training Loss: 2.3478\n",
      "Epoch: [10/20]         || Step: [400/586]       || Average Training Loss: 2.3500\n",
      "Epoch: [10/20]         || Step: [500/586]       || Average Training Loss: 2.3476\n",
      "Epoch: [10/20]         || Step: [0/47]          || Average Validation Loss: 2.4295\n",
      "****************************************************************************************************\n",
      "Epoch: [10/20] || Training Loss = 2.35 || Validation Loss: 2.30 || Time: 23.238222\n",
      "****************************************************************************************************\n",
      "Epoch: [11/20]         || Step: [0/586]         || Average Training Loss: 2.3796\n",
      "Epoch: [11/20]         || Step: [100/586]       || Average Training Loss: 2.3335\n",
      "Epoch: [11/20]         || Step: [200/586]       || Average Training Loss: 2.3342\n",
      "Epoch: [11/20]         || Step: [300/586]       || Average Training Loss: 2.3365\n",
      "Epoch: [11/20]         || Step: [400/586]       || Average Training Loss: 2.3404\n",
      "Epoch: [11/20]         || Step: [500/586]       || Average Training Loss: 2.3419\n",
      "Epoch: [11/20]         || Step: [0/47]          || Average Validation Loss: 2.2500\n",
      "****************************************************************************************************\n",
      "Epoch: [11/20] || Training Loss = 2.34 || Validation Loss: 2.30 || Time: 23.312801\n",
      "****************************************************************************************************\n",
      "Epoch: [12/20]         || Step: [0/586]         || Average Training Loss: 2.3574\n",
      "Epoch: [12/20]         || Step: [100/586]       || Average Training Loss: 2.3409\n",
      "Epoch: [12/20]         || Step: [200/586]       || Average Training Loss: 2.3371\n",
      "Epoch: [12/20]         || Step: [300/586]       || Average Training Loss: 2.3321\n",
      "Epoch: [12/20]         || Step: [400/586]       || Average Training Loss: 2.3368\n",
      "Epoch: [12/20]         || Step: [500/586]       || Average Training Loss: 2.3354\n",
      "Epoch: [12/20]         || Step: [0/47]          || Average Validation Loss: 2.3278\n",
      "****************************************************************************************************\n",
      "Epoch: [12/20] || Training Loss = 2.34 || Validation Loss: 2.29 || Time: 23.332504\n",
      "****************************************************************************************************\n",
      "Epoch: [13/20]         || Step: [0/586]         || Average Training Loss: 2.3413\n",
      "Epoch: [13/20]         || Step: [100/586]       || Average Training Loss: 2.3128\n",
      "Epoch: [13/20]         || Step: [200/586]       || Average Training Loss: 2.3252\n",
      "Epoch: [13/20]         || Step: [300/586]       || Average Training Loss: 2.3288\n",
      "Epoch: [13/20]         || Step: [400/586]       || Average Training Loss: 2.3292\n",
      "Epoch: [13/20]         || Step: [500/586]       || Average Training Loss: 2.3362\n",
      "Epoch: [13/20]         || Step: [0/47]          || Average Validation Loss: 2.3358\n",
      "****************************************************************************************************\n",
      "Epoch: [13/20] || Training Loss = 2.33 || Validation Loss: 2.29 || Time: 23.434322\n",
      "****************************************************************************************************\n",
      "Epoch: [14/20]         || Step: [0/586]         || Average Training Loss: 2.3438\n",
      "Epoch: [14/20]         || Step: [100/586]       || Average Training Loss: 2.3045\n",
      "Epoch: [14/20]         || Step: [200/586]       || Average Training Loss: 2.3150\n",
      "Epoch: [14/20]         || Step: [300/586]       || Average Training Loss: 2.3188\n",
      "Epoch: [14/20]         || Step: [400/586]       || Average Training Loss: 2.3242\n",
      "Epoch: [14/20]         || Step: [500/586]       || Average Training Loss: 2.3283\n",
      "Epoch: [14/20]         || Step: [0/47]          || Average Validation Loss: 2.3623\n",
      "****************************************************************************************************\n",
      "Epoch: [14/20] || Training Loss = 2.33 || Validation Loss: 2.29 || Time: 23.365784\n",
      "****************************************************************************************************\n",
      "Epoch: [15/20]         || Step: [0/586]         || Average Training Loss: 2.3019\n",
      "Epoch: [15/20]         || Step: [100/586]       || Average Training Loss: 2.3166\n",
      "Epoch: [15/20]         || Step: [200/586]       || Average Training Loss: 2.3205\n",
      "Epoch: [15/20]         || Step: [300/586]       || Average Training Loss: 2.3230\n",
      "Epoch: [15/20]         || Step: [400/586]       || Average Training Loss: 2.3207\n",
      "Epoch: [15/20]         || Step: [500/586]       || Average Training Loss: 2.3261\n",
      "Epoch: [15/20]         || Step: [0/47]          || Average Validation Loss: 2.1758\n",
      "****************************************************************************************************\n",
      "Epoch: [15/20] || Training Loss = 2.33 || Validation Loss: 2.29 || Time: 22.719371\n",
      "****************************************************************************************************\n",
      "Epoch: [16/20]         || Step: [0/586]         || Average Training Loss: 2.1641\n",
      "Epoch: [16/20]         || Step: [100/586]       || Average Training Loss: 2.3180\n",
      "Epoch: [16/20]         || Step: [200/586]       || Average Training Loss: 2.3221\n",
      "Epoch: [16/20]         || Step: [300/586]       || Average Training Loss: 2.3227\n",
      "Epoch: [16/20]         || Step: [400/586]       || Average Training Loss: 2.3229\n",
      "Epoch: [16/20]         || Step: [500/586]       || Average Training Loss: 2.3254\n",
      "Epoch: [16/20]         || Step: [0/47]          || Average Validation Loss: 2.4734\n",
      "****************************************************************************************************\n",
      "Epoch: [16/20] || Training Loss = 2.34 || Validation Loss: 2.40 || Time: 24.721964\n",
      "****************************************************************************************************\n",
      "Epoch: [17/20]         || Step: [0/586]         || Average Training Loss: 2.3232\n",
      "Epoch: [17/20]         || Step: [100/586]       || Average Training Loss: 2.3478\n",
      "Epoch: [17/20]         || Step: [200/586]       || Average Training Loss: 2.3423\n",
      "Epoch: [17/20]         || Step: [300/586]       || Average Training Loss: 2.3395\n",
      "Epoch: [17/20]         || Step: [400/586]       || Average Training Loss: 2.3389\n",
      "Epoch: [17/20]         || Step: [500/586]       || Average Training Loss: 2.3395\n",
      "Epoch: [17/20]         || Step: [0/47]          || Average Validation Loss: 2.1337\n",
      "****************************************************************************************************\n",
      "Epoch: [17/20] || Training Loss = 2.34 || Validation Loss: 2.30 || Time: 20.571180\n",
      "****************************************************************************************************\n",
      "Epoch: [18/20]         || Step: [0/586]         || Average Training Loss: 2.2826\n",
      "Epoch: [18/20]         || Step: [100/586]       || Average Training Loss: 2.3161\n",
      "Epoch: [18/20]         || Step: [200/586]       || Average Training Loss: 2.3182\n",
      "Epoch: [18/20]         || Step: [300/586]       || Average Training Loss: 2.3230\n",
      "Epoch: [18/20]         || Step: [400/586]       || Average Training Loss: 2.3272\n",
      "Epoch: [18/20]         || Step: [500/586]       || Average Training Loss: 2.3292\n",
      "Epoch: [18/20]         || Step: [0/47]          || Average Validation Loss: 2.2318\n",
      "****************************************************************************************************\n",
      "Epoch: [18/20] || Training Loss = 2.33 || Validation Loss: 2.31 || Time: 19.062855\n",
      "****************************************************************************************************\n",
      "Epoch: [19/20]         || Step: [0/586]         || Average Training Loss: 2.4181\n",
      "Epoch: [19/20]         || Step: [100/586]       || Average Training Loss: 2.3254\n",
      "Epoch: [19/20]         || Step: [200/586]       || Average Training Loss: 2.3151\n",
      "Epoch: [19/20]         || Step: [300/586]       || Average Training Loss: 2.3223\n",
      "Epoch: [19/20]         || Step: [400/586]       || Average Training Loss: 2.3251\n",
      "Epoch: [19/20]         || Step: [500/586]       || Average Training Loss: 2.3268\n",
      "Epoch: [19/20]         || Step: [0/47]          || Average Validation Loss: 2.3113\n",
      "****************************************************************************************************\n",
      "Epoch: [19/20] || Training Loss = 2.33 || Validation Loss: 2.29 || Time: 19.507039\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'encoder': encoder,\n",
    "    'decoder': decoder,\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'total_epoch': TOTAL_EPOCH,\n",
    "    'device': device,\n",
    "    'checkpoint_path': CHECKPOINT,\n",
    "    'print_every': PRINT_EVERY,\n",
    "    'load_checkpoint': False\n",
    "}\n",
    "\n",
    "training_loss, validation_loss = train(**train_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ea319-7ec4-4d50-88d9-7f14d809724b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
