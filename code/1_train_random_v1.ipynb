{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09b4c42",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a3db4",
   "metadata": {},
   "source": [
    "In this notebook, we will run models, also this notebook can be a template to run other models with different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606af7ca",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccfe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_loader import get_loader\n",
    "from models import Encoder, Decoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from data_prep_utils import *\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff406e5e",
   "metadata": {},
   "source": [
    "## Load train and validation loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd484d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../Datasets/coco/images/train2017'\n",
    "CAPTIONS_PATH = '../Datasets/coco/annotations/'\n",
    "#IMAGE_PATH = '../Datasets/coco/images/train2017'\n",
    "#CAPTIONS_PATH = '../Datasets/coco/annotations/' #captions_train2017.json'\n",
    "FREQ_THRESHOLD = 5\n",
    "CAPS_PER_IMAGE = 5\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "\n",
    "# root of the name to save or load captions files\n",
    "CAPTIONS_NAME = 'random_v1'\n",
    "\n",
    "# for encoder and decoder\n",
    "EMBED_SIZE = 512  # dimension of vocab embedding vector\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1  # hidden layers in LTSM\n",
    "\n",
    "# training parameters\n",
    "TOTAL_EPOCH = 50\n",
    "CHECKPOINT = '../model/model_v1'\n",
    "\n",
    "PRINT_EVERY = 100 # run print_every batches and then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a247cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 10000 images\n",
      " val dataset has 2000 images\n",
      " test dataset has 2000 images\n",
      "There are 50026 captions in the data set\n",
      "With FREQ_THRESHOLD = 5, vocab size is 3389\n"
     ]
    }
   ],
   "source": [
    "# create custom data set if we need it. We can choose to work with certain types\n",
    "# of images or reduce the size of the data\n",
    "# this will write files to 'Datasets/coco/annotations' as \n",
    "#     [save_name]_captions_train.json\n",
    "#     [save_name]_captions_val.json\n",
    "#     [save_name]_captions_test.json\n",
    "\n",
    "prepare_datasets(train_percent = 0.87, super_categories=None,\n",
    "                 max_train=10000, max_val=2000, max_test=2000,\n",
    "                 save_name=CAPTIONS_NAME, random_seed=42)\n",
    "\n",
    "# we explicitly build the vocab here. We use frequency threshold, and we build\n",
    "# vocab from the specified captions file: we're using the training data\n",
    "# we save the vocab to a name consistent with our training captions data so that \n",
    "# we can load a vocab consistent with the specific training run we've used.\n",
    "build_vocab(freq_threshold = FREQ_THRESHOLD, \n",
    "            captions_file=f'{CAPTIONS_NAME}_captions_train.json',\n",
    "            vocab_save_name=CAPTIONS_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d977f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../vocabulary/{CAPTIONS_NAME}word2idx.json', 'r') as f:\n",
    "    word2idx = json.load(f)\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4115c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataloader: 1563, Length of testing dataloader: 188\n",
      "Length of vocabulary: 3389\n"
     ]
    }
   ],
   "source": [
    "train_loader_params = {\n",
    "    'images_path': IMAGE_PATH,\n",
    "    'captions_path': CAPTIONS_PATH + f'{CAPTIONS_NAME}_captions_train.json',\n",
    "    'freq_threshold': FREQ_THRESHOLD,\n",
    "    'caps_per_image': 5,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'mode': 'train',\n",
    "    # 'idx2word': None,\n",
    "    'word2idx': word2idx\n",
    "}\n",
    "\n",
    "train_loader, train_dataset = get_loader(**train_loader_params)\n",
    "\n",
    "val_loader_params = {\n",
    "    'images_path': IMAGE_PATH,\n",
    "    'captions_path': CAPTIONS_PATH + f'{CAPTIONS_NAME}_captions_val.json',\n",
    "    'freq_threshold': FREQ_THRESHOLD,\n",
    "    'caps_per_image': 3,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': SHUFFLE,\n",
    "    'mode': 'validation',\n",
    "    # 'idx2word': train_dataset.vocab.idx2word,\n",
    "    'word2idx': word2idx\n",
    "}\n",
    "\n",
    "val_loader, val_dataset = get_loader(**val_loader_params)\n",
    "\n",
    "print(f\"Length of training dataloader: {len(train_loader)}, Length of testing dataloader: {len(val_loader)}\")\n",
    "print(f\"Length of vocabulary: {len(train_dataset.vocab.idx2word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde1d50",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593a54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"We are using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b038a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(embed_size=EMBED_SIZE, pretrained=True)\n",
    "decoder = Decoder(embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, num_layers=NUM_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fc7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is a cross entropy loss and ignore the index of <PAD> since it doesn't make any difference\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.vocab.word2idx[\"<PAD>\"]).cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss(ignore_index=train_dataset.vocab.word2idx[\"<PAD>\"])\n",
    "\n",
    "# combine the parameters of decoder and encoder\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "opt_pars = {'lr':1e-3, 'weight_decay':1e-3, 'betas':(0.9, 0.999), 'eps':1e-08}\n",
    "optimizer = optim.Adam(params, **opt_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaa922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'save_path': CHECKPOINT,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'embed_size': EMBED_SIZE,\n",
    "    'hidden_size': HIDDEN_SIZE,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'vocab_size': len(train_dataset.vocab.idx2word)\n",
    "}\n",
    "\n",
    "save_params(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14ab7da-e9af-4259-a629-994a0653050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CHECKPOINT, 'word2idx.json'), \"w\") as outfile:\n",
    "    json.dump(word2idx, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fd73a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a62141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/50]          || Step: [0/1563]        || Average Training Loss: 8.1292\n",
      "Epoch: [0/50]          || Step: [100/1563]      || Average Training Loss: 4.5479\n",
      "Epoch: [0/50]          || Step: [200/1563]      || Average Training Loss: 4.1901\n",
      "Epoch: [0/50]          || Step: [300/1563]      || Average Training Loss: 4.0170\n",
      "Epoch: [0/50]          || Step: [400/1563]      || Average Training Loss: 3.8971\n",
      "Epoch: [0/50]          || Step: [500/1563]      || Average Training Loss: 3.8081\n",
      "Epoch: [0/50]          || Step: [600/1563]      || Average Training Loss: 3.7369\n",
      "Epoch: [0/50]          || Step: [700/1563]      || Average Training Loss: 3.6792\n",
      "Epoch: [0/50]          || Step: [800/1563]      || Average Training Loss: 3.6336\n",
      "Epoch: [0/50]          || Step: [900/1563]      || Average Training Loss: 3.5957\n",
      "Epoch: [0/50]          || Step: [1000/1563]     || Average Training Loss: 3.5609\n",
      "Epoch: [0/50]          || Step: [1100/1563]     || Average Training Loss: 3.5304\n",
      "Epoch: [0/50]          || Step: [1200/1563]     || Average Training Loss: 3.5033\n",
      "Epoch: [0/50]          || Step: [1300/1563]     || Average Training Loss: 3.4809\n",
      "Epoch: [0/50]          || Step: [1400/1563]     || Average Training Loss: 3.4589\n",
      "Epoch: [0/50]          || Step: [1500/1563]     || Average Training Loss: 3.4409\n",
      "Epoch: [0/50]          || Step: [0/188]         || Average Validation Loss: 3.1906\n",
      "Epoch: [0/50]          || Step: [100/188]       || Average Validation Loss: 3.1184\n",
      "****************************************************************************************************\n",
      "Epoch: [0/50] || Training Loss = 3.43 || Validation Loss: 3.14 || Time: 16.653658\n",
      "****************************************************************************************************\n",
      "Epoch: [1/50]          || Step: [0/1563]        || Average Training Loss: 3.0542\n",
      "Epoch: [1/50]          || Step: [100/1563]      || Average Training Loss: 3.1861\n",
      "Epoch: [1/50]          || Step: [200/1563]      || Average Training Loss: 3.1718\n",
      "Epoch: [1/50]          || Step: [300/1563]      || Average Training Loss: 3.1757\n",
      "Epoch: [1/50]          || Step: [400/1563]      || Average Training Loss: 3.1678\n",
      "Epoch: [1/50]          || Step: [500/1563]      || Average Training Loss: 3.1628\n",
      "Epoch: [1/50]          || Step: [600/1563]      || Average Training Loss: 3.1634\n",
      "Epoch: [1/50]          || Step: [700/1563]      || Average Training Loss: 3.1596\n",
      "Epoch: [1/50]          || Step: [800/1563]      || Average Training Loss: 3.1607\n",
      "Epoch: [1/50]          || Step: [900/1563]      || Average Training Loss: 3.1618\n",
      "Epoch: [1/50]          || Step: [1000/1563]     || Average Training Loss: 3.1626\n",
      "Epoch: [1/50]          || Step: [1100/1563]     || Average Training Loss: 3.1626\n",
      "Epoch: [1/50]          || Step: [1200/1563]     || Average Training Loss: 3.1630\n",
      "Epoch: [1/50]          || Step: [1300/1563]     || Average Training Loss: 3.1622\n",
      "Epoch: [1/50]          || Step: [1400/1563]     || Average Training Loss: 3.1636\n",
      "Epoch: [1/50]          || Step: [1500/1563]     || Average Training Loss: 3.1656\n",
      "Epoch: [1/50]          || Step: [0/188]         || Average Validation Loss: 3.0876\n",
      "Epoch: [1/50]          || Step: [100/188]       || Average Validation Loss: 3.1275\n",
      "****************************************************************************************************\n",
      "Epoch: [1/50] || Training Loss = 3.17 || Validation Loss: 3.12 || Time: 34.010769\n",
      "****************************************************************************************************\n",
      "Epoch: [2/50]          || Step: [0/1563]        || Average Training Loss: 2.9605\n",
      "Epoch: [2/50]          || Step: [100/1563]      || Average Training Loss: 3.1378\n",
      "Epoch: [2/50]          || Step: [200/1563]      || Average Training Loss: 3.1411\n",
      "Epoch: [2/50]          || Step: [300/1563]      || Average Training Loss: 3.1536\n",
      "Epoch: [2/50]          || Step: [400/1563]      || Average Training Loss: 3.1609\n",
      "Epoch: [2/50]          || Step: [500/1563]      || Average Training Loss: 3.1643\n",
      "Epoch: [2/50]          || Step: [600/1563]      || Average Training Loss: 3.1644\n",
      "Epoch: [2/50]          || Step: [700/1563]      || Average Training Loss: 3.1670\n",
      "Epoch: [2/50]          || Step: [800/1563]      || Average Training Loss: 3.1669\n",
      "Epoch: [2/50]          || Step: [900/1563]      || Average Training Loss: 3.1641\n",
      "Epoch: [2/50]          || Step: [1000/1563]     || Average Training Loss: 3.1665\n",
      "Epoch: [2/50]          || Step: [1100/1563]     || Average Training Loss: 3.1662\n",
      "Epoch: [2/50]          || Step: [1200/1563]     || Average Training Loss: 3.1676\n",
      "Epoch: [2/50]          || Step: [1300/1563]     || Average Training Loss: 3.1662\n",
      "Epoch: [2/50]          || Step: [1400/1563]     || Average Training Loss: 3.1649\n",
      "Epoch: [2/50]          || Step: [1500/1563]     || Average Training Loss: 3.1648\n",
      "Epoch: [2/50]          || Step: [0/188]         || Average Validation Loss: 3.5126\n",
      "Epoch: [2/50]          || Step: [100/188]       || Average Validation Loss: 3.1335\n",
      "****************************************************************************************************\n",
      "Epoch: [2/50] || Training Loss = 3.16 || Validation Loss: 3.12 || Time: 51.082519\n",
      "****************************************************************************************************\n",
      "Epoch: [3/50]          || Step: [0/1563]        || Average Training Loss: 3.1060\n",
      "Epoch: [3/50]          || Step: [100/1563]      || Average Training Loss: 3.1343\n",
      "Epoch: [3/50]          || Step: [200/1563]      || Average Training Loss: 3.1413\n",
      "Epoch: [3/50]          || Step: [300/1563]      || Average Training Loss: 3.1330\n",
      "Epoch: [3/50]          || Step: [400/1563]      || Average Training Loss: 3.1371\n",
      "Epoch: [3/50]          || Step: [500/1563]      || Average Training Loss: 3.1481\n",
      "Epoch: [3/50]          || Step: [600/1563]      || Average Training Loss: 3.1495\n",
      "Epoch: [3/50]          || Step: [700/1563]      || Average Training Loss: 3.1481\n",
      "Epoch: [3/50]          || Step: [800/1563]      || Average Training Loss: 3.1490\n",
      "Epoch: [3/50]          || Step: [900/1563]      || Average Training Loss: 3.1473\n",
      "Epoch: [3/50]          || Step: [1000/1563]     || Average Training Loss: 3.1468\n",
      "Epoch: [3/50]          || Step: [1100/1563]     || Average Training Loss: 3.1449\n",
      "Epoch: [3/50]          || Step: [1200/1563]     || Average Training Loss: 3.1435\n",
      "Epoch: [3/50]          || Step: [1300/1563]     || Average Training Loss: 3.1423\n",
      "Epoch: [3/50]          || Step: [1400/1563]     || Average Training Loss: 3.1439\n",
      "Epoch: [3/50]          || Step: [1500/1563]     || Average Training Loss: 3.1447\n",
      "Epoch: [3/50]          || Step: [0/188]         || Average Validation Loss: 3.1167\n",
      "Epoch: [3/50]          || Step: [100/188]       || Average Validation Loss: 3.0761\n",
      "****************************************************************************************************\n",
      "Epoch: [3/50] || Training Loss = 3.14 || Validation Loss: 3.09 || Time: 68.306114\n",
      "****************************************************************************************************\n",
      "Epoch: [4/50]          || Step: [0/1563]        || Average Training Loss: 3.1570\n",
      "Epoch: [4/50]          || Step: [100/1563]      || Average Training Loss: 3.1197\n",
      "Epoch: [4/50]          || Step: [200/1563]      || Average Training Loss: 3.1336\n",
      "Epoch: [4/50]          || Step: [300/1563]      || Average Training Loss: 3.1295\n",
      "Epoch: [4/50]          || Step: [400/1563]      || Average Training Loss: 3.1279\n",
      "Epoch: [4/50]          || Step: [500/1563]      || Average Training Loss: 3.1305\n",
      "Epoch: [4/50]          || Step: [600/1563]      || Average Training Loss: 3.1300\n",
      "Epoch: [4/50]          || Step: [700/1563]      || Average Training Loss: 3.1276\n",
      "Epoch: [4/50]          || Step: [800/1563]      || Average Training Loss: 3.1293\n",
      "Epoch: [4/50]          || Step: [900/1563]      || Average Training Loss: 3.1303\n",
      "Epoch: [4/50]          || Step: [1000/1563]     || Average Training Loss: 3.1271\n",
      "Epoch: [4/50]          || Step: [1100/1563]     || Average Training Loss: 3.1282\n",
      "Epoch: [4/50]          || Step: [1200/1563]     || Average Training Loss: 3.1286\n",
      "Epoch: [4/50]          || Step: [1300/1563]     || Average Training Loss: 3.1302\n",
      "Epoch: [4/50]          || Step: [1400/1563]     || Average Training Loss: 3.1298\n",
      "Epoch: [4/50]          || Step: [1500/1563]     || Average Training Loss: 3.1281\n",
      "Epoch: [4/50]          || Step: [0/188]         || Average Validation Loss: 3.1069\n",
      "Epoch: [4/50]          || Step: [100/188]       || Average Validation Loss: 3.0903\n",
      "****************************************************************************************************\n",
      "Epoch: [4/50] || Training Loss = 3.13 || Validation Loss: 3.08 || Time: 85.513001\n",
      "****************************************************************************************************\n",
      "Epoch: [5/50]          || Step: [0/1563]        || Average Training Loss: 3.0855\n",
      "Epoch: [5/50]          || Step: [100/1563]      || Average Training Loss: 3.0862\n",
      "Epoch: [5/50]          || Step: [200/1563]      || Average Training Loss: 3.1012\n",
      "Epoch: [5/50]          || Step: [300/1563]      || Average Training Loss: 3.0990\n",
      "Epoch: [5/50]          || Step: [400/1563]      || Average Training Loss: 3.1054\n",
      "Epoch: [5/50]          || Step: [500/1563]      || Average Training Loss: 3.1049\n",
      "Epoch: [5/50]          || Step: [600/1563]      || Average Training Loss: 3.1072\n",
      "Epoch: [5/50]          || Step: [700/1563]      || Average Training Loss: 3.1069\n",
      "Epoch: [5/50]          || Step: [800/1563]      || Average Training Loss: 3.1081\n",
      "Epoch: [5/50]          || Step: [900/1563]      || Average Training Loss: 3.1095\n",
      "Epoch: [5/50]          || Step: [1000/1563]     || Average Training Loss: 3.1104\n",
      "Epoch: [5/50]          || Step: [1100/1563]     || Average Training Loss: 3.1109\n",
      "Epoch: [5/50]          || Step: [1200/1563]     || Average Training Loss: 3.1108\n",
      "Epoch: [5/50]          || Step: [1300/1563]     || Average Training Loss: 3.1134\n",
      "Epoch: [5/50]          || Step: [1400/1563]     || Average Training Loss: 3.1135\n",
      "Epoch: [5/50]          || Step: [1500/1563]     || Average Training Loss: 3.1147\n",
      "Epoch: [5/50]          || Step: [0/188]         || Average Validation Loss: 2.8950\n",
      "Epoch: [5/50]          || Step: [100/188]       || Average Validation Loss: 3.0784\n",
      "****************************************************************************************************\n",
      "Epoch: [5/50] || Training Loss = 3.12 || Validation Loss: 3.07 || Time: 102.820003\n",
      "****************************************************************************************************\n",
      "Epoch: [6/50]          || Step: [0/1563]        || Average Training Loss: 3.0326\n",
      "Epoch: [6/50]          || Step: [100/1563]      || Average Training Loss: 3.0677\n",
      "Epoch: [6/50]          || Step: [200/1563]      || Average Training Loss: 3.0980\n",
      "Epoch: [6/50]          || Step: [300/1563]      || Average Training Loss: 3.1075\n",
      "Epoch: [6/50]          || Step: [400/1563]      || Average Training Loss: 3.1033\n",
      "Epoch: [6/50]          || Step: [500/1563]      || Average Training Loss: 3.1064\n",
      "Epoch: [6/50]          || Step: [600/1563]      || Average Training Loss: 3.1080\n",
      "Epoch: [6/50]          || Step: [700/1563]      || Average Training Loss: 3.1014\n",
      "Epoch: [6/50]          || Step: [900/1563]      || Average Training Loss: 3.1061\n",
      "Epoch: [6/50]          || Step: [1000/1563]     || Average Training Loss: 3.1027\n",
      "Epoch: [6/50]          || Step: [1100/1563]     || Average Training Loss: 3.1036\n",
      "Epoch: [6/50]          || Step: [1200/1563]     || Average Training Loss: 3.1027\n",
      "Epoch: [6/50]          || Step: [1300/1563]     || Average Training Loss: 3.1047\n",
      "Epoch: [6/50]          || Step: [1400/1563]     || Average Training Loss: 3.1036\n",
      "Epoch: [6/50]          || Step: [1500/1563]     || Average Training Loss: 3.1052\n",
      "Epoch: [6/50]          || Step: [0/188]         || Average Validation Loss: 3.0607\n",
      "Epoch: [6/50]          || Step: [100/188]       || Average Validation Loss: 3.0820\n",
      "****************************************************************************************************\n",
      "Epoch: [6/50] || Training Loss = 3.11 || Validation Loss: 3.06 || Time: 120.360225\n",
      "****************************************************************************************************\n",
      "Epoch: [7/50]          || Step: [0/1563]        || Average Training Loss: 2.6445\n",
      "Epoch: [7/50]          || Step: [100/1563]      || Average Training Loss: 3.0744\n",
      "Epoch: [7/50]          || Step: [200/1563]      || Average Training Loss: 3.0812\n",
      "Epoch: [7/50]          || Step: [300/1563]      || Average Training Loss: 3.0979\n",
      "Epoch: [7/50]          || Step: [400/1563]      || Average Training Loss: 3.0952\n",
      "Epoch: [7/50]          || Step: [500/1563]      || Average Training Loss: 3.0976\n",
      "Epoch: [7/50]          || Step: [600/1563]      || Average Training Loss: 3.0957\n",
      "Epoch: [7/50]          || Step: [700/1563]      || Average Training Loss: 3.0999\n",
      "Epoch: [7/50]          || Step: [800/1563]      || Average Training Loss: 3.0970\n",
      "Epoch: [7/50]          || Step: [900/1563]      || Average Training Loss: 3.0975\n",
      "Epoch: [7/50]          || Step: [1000/1563]     || Average Training Loss: 3.0987\n",
      "Epoch: [7/50]          || Step: [1100/1563]     || Average Training Loss: 3.0988\n",
      "Epoch: [7/50]          || Step: [1200/1563]     || Average Training Loss: 3.0982\n",
      "Epoch: [7/50]          || Step: [1300/1563]     || Average Training Loss: 3.0992\n",
      "Epoch: [7/50]          || Step: [1400/1563]     || Average Training Loss: 3.0989\n",
      "Epoch: [7/50]          || Step: [1500/1563]     || Average Training Loss: 3.0984\n",
      "Epoch: [7/50]          || Step: [0/188]         || Average Validation Loss: 3.1319\n",
      "Epoch: [7/50]          || Step: [100/188]       || Average Validation Loss: 3.0485\n",
      "****************************************************************************************************\n",
      "Epoch: [7/50] || Training Loss = 3.10 || Validation Loss: 3.07 || Time: 139.258675\n",
      "****************************************************************************************************\n",
      "Epoch: [8/50]          || Step: [0/1563]        || Average Training Loss: 3.1995\n",
      "Epoch: [8/50]          || Step: [100/1563]      || Average Training Loss: 3.0771\n",
      "Epoch: [8/50]          || Step: [200/1563]      || Average Training Loss: 3.0825\n",
      "Epoch: [8/50]          || Step: [300/1563]      || Average Training Loss: 3.0929\n",
      "Epoch: [8/50]          || Step: [400/1563]      || Average Training Loss: 3.0971\n",
      "Epoch: [8/50]          || Step: [500/1563]      || Average Training Loss: 3.1023\n",
      "Epoch: [8/50]          || Step: [600/1563]      || Average Training Loss: 3.0986\n",
      "Epoch: [8/50]          || Step: [700/1563]      || Average Training Loss: 3.0952\n",
      "Epoch: [8/50]          || Step: [800/1563]      || Average Training Loss: 3.0928\n",
      "Epoch: [8/50]          || Step: [900/1563]      || Average Training Loss: 3.0930\n",
      "Epoch: [8/50]          || Step: [1000/1563]     || Average Training Loss: 3.0934\n",
      "Epoch: [8/50]          || Step: [1100/1563]     || Average Training Loss: 3.0942\n",
      "Epoch: [8/50]          || Step: [1200/1563]     || Average Training Loss: 3.0924\n",
      "Epoch: [8/50]          || Step: [1300/1563]     || Average Training Loss: 3.0918\n",
      "Epoch: [8/50]          || Step: [1400/1563]     || Average Training Loss: 3.0937\n",
      "Epoch: [8/50]          || Step: [1500/1563]     || Average Training Loss: 3.0938\n",
      "Epoch: [8/50]          || Step: [0/188]         || Average Validation Loss: 2.9447\n",
      "Epoch: [8/50]          || Step: [100/188]       || Average Validation Loss: 3.0543\n",
      "****************************************************************************************************\n",
      "Epoch: [8/50] || Training Loss = 3.09 || Validation Loss: 3.05 || Time: 160.070075\n",
      "****************************************************************************************************\n",
      "Epoch: [9/50]          || Step: [0/1563]        || Average Training Loss: 2.9188\n",
      "Epoch: [9/50]          || Step: [100/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [9/50]          || Step: [200/1563]      || Average Training Loss: 3.0803\n",
      "Epoch: [9/50]          || Step: [300/1563]      || Average Training Loss: 3.0831\n",
      "Epoch: [9/50]          || Step: [400/1563]      || Average Training Loss: 3.0834\n",
      "Epoch: [9/50]          || Step: [500/1563]      || Average Training Loss: 3.0913\n",
      "Epoch: [9/50]          || Step: [600/1563]      || Average Training Loss: 3.0913\n",
      "Epoch: [9/50]          || Step: [700/1563]      || Average Training Loss: 3.0899\n",
      "Epoch: [9/50]          || Step: [800/1563]      || Average Training Loss: 3.0905\n",
      "Epoch: [9/50]          || Step: [900/1563]      || Average Training Loss: 3.0916\n",
      "Epoch: [9/50]          || Step: [1000/1563]     || Average Training Loss: 3.0901\n",
      "Epoch: [9/50]          || Step: [1100/1563]     || Average Training Loss: 3.0900\n",
      "Epoch: [9/50]          || Step: [1200/1563]     || Average Training Loss: 3.0907\n",
      "Epoch: [9/50]          || Step: [1300/1563]     || Average Training Loss: 3.0887\n",
      "Epoch: [9/50]          || Step: [1400/1563]     || Average Training Loss: 3.0864\n",
      "Epoch: [9/50]          || Step: [1500/1563]     || Average Training Loss: 3.0878\n",
      "Epoch: [9/50]          || Step: [0/188]         || Average Validation Loss: 2.9263\n",
      "Epoch: [9/50]          || Step: [100/188]       || Average Validation Loss: 3.0511\n",
      "****************************************************************************************************\n",
      "Epoch: [9/50] || Training Loss = 3.09 || Validation Loss: 3.05 || Time: 177.550000\n",
      "****************************************************************************************************\n",
      "Epoch: [10/50]         || Step: [0/1563]        || Average Training Loss: 3.3025\n",
      "Epoch: [10/50]         || Step: [300/1563]      || Average Training Loss: 3.0664\n",
      "Epoch: [10/50]         || Step: [400/1563]      || Average Training Loss: 3.0764\n",
      "Epoch: [10/50]         || Step: [500/1563]      || Average Training Loss: 3.0824\n",
      "Epoch: [10/50]         || Step: [600/1563]      || Average Training Loss: 3.0861\n",
      "Epoch: [10/50]         || Step: [700/1563]      || Average Training Loss: 3.0874\n",
      "Epoch: [10/50]         || Step: [800/1563]      || Average Training Loss: 3.0870\n",
      "Epoch: [10/50]         || Step: [900/1563]      || Average Training Loss: 3.0873\n",
      "Epoch: [10/50]         || Step: [1000/1563]     || Average Training Loss: 3.0912\n",
      "Epoch: [10/50]         || Step: [1100/1563]     || Average Training Loss: 3.0894\n",
      "Epoch: [10/50]         || Step: [1200/1563]     || Average Training Loss: 3.0892\n",
      "Epoch: [10/50]         || Step: [1300/1563]     || Average Training Loss: 3.0893\n",
      "Epoch: [10/50]         || Step: [1400/1563]     || Average Training Loss: 3.0905\n",
      "Epoch: [10/50]         || Step: [1500/1563]     || Average Training Loss: 3.0902\n",
      "Epoch: [10/50]         || Step: [0/188]         || Average Validation Loss: 3.3591\n",
      "Epoch: [10/50]         || Step: [100/188]       || Average Validation Loss: 3.0445\n",
      "****************************************************************************************************\n",
      "Epoch: [10/50] || Training Loss = 3.09 || Validation Loss: 3.04 || Time: 195.205409\n",
      "****************************************************************************************************\n",
      "Epoch: [11/50]         || Step: [0/1563]        || Average Training Loss: 3.2374\n",
      "Epoch: [11/50]         || Step: [100/1563]      || Average Training Loss: 3.0748\n",
      "Epoch: [11/50]         || Step: [200/1563]      || Average Training Loss: 3.0720\n",
      "Epoch: [11/50]         || Step: [300/1563]      || Average Training Loss: 3.0684\n",
      "Epoch: [11/50]         || Step: [400/1563]      || Average Training Loss: 3.0738\n",
      "Epoch: [11/50]         || Step: [500/1563]      || Average Training Loss: 3.0721\n",
      "Epoch: [11/50]         || Step: [600/1563]      || Average Training Loss: 3.0695\n",
      "Epoch: [11/50]         || Step: [700/1563]      || Average Training Loss: 3.0708\n",
      "Epoch: [11/50]         || Step: [800/1563]      || Average Training Loss: 3.0729\n",
      "Epoch: [11/50]         || Step: [900/1563]      || Average Training Loss: 3.0727\n",
      "Epoch: [11/50]         || Step: [1000/1563]     || Average Training Loss: 3.0752\n",
      "Epoch: [11/50]         || Step: [1100/1563]     || Average Training Loss: 3.0771\n",
      "Epoch: [11/50]         || Step: [1200/1563]     || Average Training Loss: 3.0790\n",
      "Epoch: [11/50]         || Step: [1300/1563]     || Average Training Loss: 3.0805\n",
      "Epoch: [11/50]         || Step: [1400/1563]     || Average Training Loss: 3.0810\n",
      "Epoch: [11/50]         || Step: [1500/1563]     || Average Training Loss: 3.0825\n",
      "Epoch: [11/50]         || Step: [0/188]         || Average Validation Loss: 3.0387\n",
      "Epoch: [11/50]         || Step: [100/188]       || Average Validation Loss: 3.0488\n",
      "****************************************************************************************************\n",
      "Epoch: [11/50] || Training Loss = 3.08 || Validation Loss: 3.04 || Time: 212.818346\n",
      "****************************************************************************************************\n",
      "Epoch: [12/50]         || Step: [0/1563]        || Average Training Loss: 3.1331\n",
      "Epoch: [12/50]         || Step: [100/1563]      || Average Training Loss: 3.0657\n",
      "Epoch: [12/50]         || Step: [200/1563]      || Average Training Loss: 3.0786\n",
      "Epoch: [12/50]         || Step: [300/1563]      || Average Training Loss: 3.0810\n",
      "Epoch: [12/50]         || Step: [400/1563]      || Average Training Loss: 3.0792\n",
      "Epoch: [12/50]         || Step: [500/1563]      || Average Training Loss: 3.0835\n",
      "Epoch: [12/50]         || Step: [600/1563]      || Average Training Loss: 3.0850\n",
      "Epoch: [12/50]         || Step: [700/1563]      || Average Training Loss: 3.0862\n",
      "Epoch: [12/50]         || Step: [800/1563]      || Average Training Loss: 3.0867\n",
      "Epoch: [12/50]         || Step: [900/1563]      || Average Training Loss: 3.0849\n",
      "Epoch: [12/50]         || Step: [1000/1563]     || Average Training Loss: 3.0816\n",
      "Epoch: [12/50]         || Step: [1100/1563]     || Average Training Loss: 3.0817\n",
      "Epoch: [12/50]         || Step: [1200/1563]     || Average Training Loss: 3.0819\n",
      "Epoch: [12/50]         || Step: [1300/1563]     || Average Training Loss: 3.0821\n",
      "Epoch: [12/50]         || Step: [1400/1563]     || Average Training Loss: 3.0821\n",
      "Epoch: [12/50]         || Step: [1500/1563]     || Average Training Loss: 3.0818\n",
      "Epoch: [12/50]         || Step: [0/188]         || Average Validation Loss: 3.2735\n",
      "Epoch: [12/50]         || Step: [100/188]       || Average Validation Loss: 3.0404\n",
      "****************************************************************************************************\n",
      "Epoch: [12/50] || Training Loss = 3.08 || Validation Loss: 3.04 || Time: 230.468957\n",
      "****************************************************************************************************\n",
      "Epoch: [13/50]         || Step: [0/1563]        || Average Training Loss: 3.1608\n",
      "Epoch: [13/50]         || Step: [100/1563]      || Average Training Loss: 3.0759\n",
      "Epoch: [13/50]         || Step: [200/1563]      || Average Training Loss: 3.0804\n",
      "Epoch: [13/50]         || Step: [300/1563]      || Average Training Loss: 3.0745\n",
      "Epoch: [13/50]         || Step: [400/1563]      || Average Training Loss: 3.0826\n",
      "Epoch: [13/50]         || Step: [500/1563]      || Average Training Loss: 3.0833\n",
      "Epoch: [13/50]         || Step: [600/1563]      || Average Training Loss: 3.0800\n",
      "Epoch: [13/50]         || Step: [700/1563]      || Average Training Loss: 3.0799\n",
      "Epoch: [13/50]         || Step: [800/1563]      || Average Training Loss: 3.0823\n",
      "Epoch: [13/50]         || Step: [900/1563]      || Average Training Loss: 3.0780\n",
      "Epoch: [13/50]         || Step: [1000/1563]     || Average Training Loss: 3.0799\n",
      "Epoch: [13/50]         || Step: [1100/1563]     || Average Training Loss: 3.0782\n",
      "Epoch: [13/50]         || Step: [1200/1563]     || Average Training Loss: 3.0778\n",
      "Epoch: [13/50]         || Step: [1300/1563]     || Average Training Loss: 3.0787\n",
      "Epoch: [13/50]         || Step: [1400/1563]     || Average Training Loss: 3.0788\n",
      "Epoch: [13/50]         || Step: [1500/1563]     || Average Training Loss: 3.0794\n",
      "Epoch: [13/50]         || Step: [0/188]         || Average Validation Loss: 3.3027\n",
      "Epoch: [13/50]         || Step: [100/188]       || Average Validation Loss: 3.0574\n",
      "****************************************************************************************************\n",
      "Epoch: [13/50] || Training Loss = 3.08 || Validation Loss: 3.03 || Time: 247.980938\n",
      "****************************************************************************************************\n",
      "Epoch: [14/50]         || Step: [0/1563]        || Average Training Loss: 3.1098\n",
      "Epoch: [14/50]         || Step: [100/1563]      || Average Training Loss: 3.0727\n",
      "Epoch: [14/50]         || Step: [200/1563]      || Average Training Loss: 3.0691\n",
      "Epoch: [14/50]         || Step: [300/1563]      || Average Training Loss: 3.0638\n",
      "Epoch: [14/50]         || Step: [400/1563]      || Average Training Loss: 3.0697\n",
      "Epoch: [14/50]         || Step: [500/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [14/50]         || Step: [600/1563]      || Average Training Loss: 3.0711\n",
      "Epoch: [14/50]         || Step: [700/1563]      || Average Training Loss: 3.0778\n",
      "Epoch: [14/50]         || Step: [800/1563]      || Average Training Loss: 3.0788\n",
      "Epoch: [14/50]         || Step: [900/1563]      || Average Training Loss: 3.0764\n",
      "Epoch: [14/50]         || Step: [1000/1563]     || Average Training Loss: 3.0795\n",
      "Epoch: [14/50]         || Step: [1100/1563]     || Average Training Loss: 3.0762\n",
      "Epoch: [14/50]         || Step: [1200/1563]     || Average Training Loss: 3.0762\n",
      "Epoch: [14/50]         || Step: [1300/1563]     || Average Training Loss: 3.0767\n",
      "Epoch: [14/50]         || Step: [1400/1563]     || Average Training Loss: 3.0772\n",
      "Epoch: [14/50]         || Step: [1500/1563]     || Average Training Loss: 3.0772\n",
      "Epoch: [14/50]         || Step: [0/188]         || Average Validation Loss: 3.2201\n",
      "Epoch: [14/50]         || Step: [100/188]       || Average Validation Loss: 3.0477\n",
      "****************************************************************************************************\n",
      "Epoch: [14/50] || Training Loss = 3.08 || Validation Loss: 3.04 || Time: 265.544757\n",
      "****************************************************************************************************\n",
      "Epoch: [15/50]         || Step: [0/1563]        || Average Training Loss: 3.5004\n",
      "Epoch: [15/50]         || Step: [100/1563]      || Average Training Loss: 3.0482\n",
      "Epoch: [15/50]         || Step: [200/1563]      || Average Training Loss: 3.0512\n",
      "Epoch: [15/50]         || Step: [300/1563]      || Average Training Loss: 3.0567\n",
      "Epoch: [15/50]         || Step: [400/1563]      || Average Training Loss: 3.0610\n",
      "Epoch: [15/50]         || Step: [500/1563]      || Average Training Loss: 3.0666\n",
      "Epoch: [15/50]         || Step: [600/1563]      || Average Training Loss: 3.0693\n",
      "Epoch: [15/50]         || Step: [700/1563]      || Average Training Loss: 3.0722\n",
      "Epoch: [15/50]         || Step: [800/1563]      || Average Training Loss: 3.0717\n",
      "Epoch: [15/50]         || Step: [900/1563]      || Average Training Loss: 3.0709\n",
      "Epoch: [15/50]         || Step: [1000/1563]     || Average Training Loss: 3.0710\n",
      "Epoch: [15/50]         || Step: [1100/1563]     || Average Training Loss: 3.0701\n",
      "Epoch: [15/50]         || Step: [1200/1563]     || Average Training Loss: 3.0715\n",
      "Epoch: [15/50]         || Step: [1300/1563]     || Average Training Loss: 3.0719\n",
      "Epoch: [15/50]         || Step: [1400/1563]     || Average Training Loss: 3.0723\n",
      "Epoch: [15/50]         || Step: [1500/1563]     || Average Training Loss: 3.0733\n",
      "Epoch: [15/50]         || Step: [0/188]         || Average Validation Loss: 3.0322\n",
      "Epoch: [15/50]         || Step: [100/188]       || Average Validation Loss: 3.0531\n",
      "****************************************************************************************************\n",
      "Epoch: [15/50] || Training Loss = 3.08 || Validation Loss: 3.05 || Time: 283.102242\n",
      "****************************************************************************************************\n",
      "Epoch: [16/50]         || Step: [0/1563]        || Average Training Loss: 2.9248\n",
      "Epoch: [16/50]         || Step: [100/1563]      || Average Training Loss: 3.0629\n",
      "Epoch: [16/50]         || Step: [200/1563]      || Average Training Loss: 3.0619\n",
      "Epoch: [16/50]         || Step: [300/1563]      || Average Training Loss: 3.0667\n",
      "Epoch: [16/50]         || Step: [400/1563]      || Average Training Loss: 3.0687\n",
      "Epoch: [16/50]         || Step: [500/1563]      || Average Training Loss: 3.0697\n",
      "Epoch: [16/50]         || Step: [600/1563]      || Average Training Loss: 3.0716\n",
      "Epoch: [16/50]         || Step: [700/1563]      || Average Training Loss: 3.0722\n",
      "Epoch: [16/50]         || Step: [800/1563]      || Average Training Loss: 3.0724\n",
      "Epoch: [16/50]         || Step: [900/1563]      || Average Training Loss: 3.0743\n",
      "Epoch: [16/50]         || Step: [1000/1563]     || Average Training Loss: 3.0731\n",
      "Epoch: [16/50]         || Step: [1100/1563]     || Average Training Loss: 3.0750\n",
      "Epoch: [16/50]         || Step: [1200/1563]     || Average Training Loss: 3.0764\n",
      "Epoch: [16/50]         || Step: [1300/1563]     || Average Training Loss: 3.0755\n",
      "Epoch: [16/50]         || Step: [1400/1563]     || Average Training Loss: 3.0745\n",
      "Epoch: [16/50]         || Step: [1500/1563]     || Average Training Loss: 3.0749\n",
      "Epoch: [16/50]         || Step: [0/188]         || Average Validation Loss: 3.0429\n",
      "Epoch: [16/50]         || Step: [100/188]       || Average Validation Loss: 3.0444\n",
      "****************************************************************************************************\n",
      "Epoch: [16/50] || Training Loss = 3.08 || Validation Loss: 3.04 || Time: 300.768644\n",
      "****************************************************************************************************\n",
      "Epoch: [17/50]         || Step: [0/1563]        || Average Training Loss: 3.1270\n",
      "Epoch: [17/50]         || Step: [100/1563]      || Average Training Loss: 3.0537\n",
      "Epoch: [17/50]         || Step: [200/1563]      || Average Training Loss: 3.0687\n",
      "Epoch: [17/50]         || Step: [300/1563]      || Average Training Loss: 3.0649\n",
      "Epoch: [17/50]         || Step: [400/1563]      || Average Training Loss: 3.0723\n",
      "Epoch: [17/50]         || Step: [500/1563]      || Average Training Loss: 3.0695\n",
      "Epoch: [17/50]         || Step: [600/1563]      || Average Training Loss: 3.0729\n",
      "Epoch: [17/50]         || Step: [700/1563]      || Average Training Loss: 3.0728\n",
      "Epoch: [17/50]         || Step: [800/1563]      || Average Training Loss: 3.0741\n",
      "Epoch: [17/50]         || Step: [900/1563]      || Average Training Loss: 3.0750\n",
      "Epoch: [17/50]         || Step: [1000/1563]     || Average Training Loss: 3.0740\n",
      "Epoch: [17/50]         || Step: [1100/1563]     || Average Training Loss: 3.0743\n",
      "Epoch: [17/50]         || Step: [1200/1563]     || Average Training Loss: 3.0755\n",
      "Epoch: [17/50]         || Step: [1300/1563]     || Average Training Loss: 3.0737\n",
      "Epoch: [17/50]         || Step: [1400/1563]     || Average Training Loss: 3.0729\n",
      "Epoch: [17/50]         || Step: [1500/1563]     || Average Training Loss: 3.0731\n",
      "Epoch: [17/50]         || Step: [0/188]         || Average Validation Loss: 2.9339\n",
      "Epoch: [17/50]         || Step: [100/188]       || Average Validation Loss: 3.0144\n",
      "****************************************************************************************************\n",
      "Epoch: [17/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 318.305935\n",
      "****************************************************************************************************\n",
      "Epoch: [18/50]         || Step: [0/1563]        || Average Training Loss: 3.3584\n",
      "Epoch: [18/50]         || Step: [100/1563]      || Average Training Loss: 3.0611\n",
      "Epoch: [18/50]         || Step: [200/1563]      || Average Training Loss: 3.0538\n",
      "Epoch: [18/50]         || Step: [300/1563]      || Average Training Loss: 3.0658\n",
      "Epoch: [18/50]         || Step: [400/1563]      || Average Training Loss: 3.0629\n",
      "Epoch: [18/50]         || Step: [500/1563]      || Average Training Loss: 3.0616\n",
      "Epoch: [18/50]         || Step: [600/1563]      || Average Training Loss: 3.0613\n",
      "Epoch: [18/50]         || Step: [700/1563]      || Average Training Loss: 3.0633\n",
      "Epoch: [18/50]         || Step: [800/1563]      || Average Training Loss: 3.0654\n",
      "Epoch: [18/50]         || Step: [900/1563]      || Average Training Loss: 3.0689\n",
      "Epoch: [18/50]         || Step: [1000/1563]     || Average Training Loss: 3.0704\n",
      "Epoch: [18/50]         || Step: [1100/1563]     || Average Training Loss: 3.0693\n",
      "Epoch: [18/50]         || Step: [1200/1563]     || Average Training Loss: 3.0733\n",
      "Epoch: [18/50]         || Step: [1300/1563]     || Average Training Loss: 3.0752\n",
      "Epoch: [18/50]         || Step: [1400/1563]     || Average Training Loss: 3.0734\n",
      "Epoch: [18/50]         || Step: [1500/1563]     || Average Training Loss: 3.0730\n",
      "Epoch: [18/50]         || Step: [0/188]         || Average Validation Loss: 2.9618\n",
      "Epoch: [18/50]         || Step: [100/188]       || Average Validation Loss: 3.0458\n",
      "****************************************************************************************************\n",
      "Epoch: [18/50] || Training Loss = 3.07 || Validation Loss: 3.05 || Time: 335.796126\n",
      "****************************************************************************************************\n",
      "Epoch: [19/50]         || Step: [0/1563]        || Average Training Loss: 3.2447\n",
      "Epoch: [19/50]         || Step: [100/1563]      || Average Training Loss: 3.0630\n",
      "Epoch: [19/50]         || Step: [200/1563]      || Average Training Loss: 3.0598\n",
      "Epoch: [19/50]         || Step: [300/1563]      || Average Training Loss: 3.0678\n",
      "Epoch: [19/50]         || Step: [400/1563]      || Average Training Loss: 3.0656\n",
      "Epoch: [19/50]         || Step: [500/1563]      || Average Training Loss: 3.0705\n",
      "Epoch: [19/50]         || Step: [600/1563]      || Average Training Loss: 3.0704\n",
      "Epoch: [19/50]         || Step: [700/1563]      || Average Training Loss: 3.0692\n",
      "Epoch: [19/50]         || Step: [800/1563]      || Average Training Loss: 3.0697\n",
      "Epoch: [19/50]         || Step: [900/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [19/50]         || Step: [1000/1563]     || Average Training Loss: 3.0676\n",
      "Epoch: [19/50]         || Step: [1100/1563]     || Average Training Loss: 3.0706\n",
      "Epoch: [19/50]         || Step: [1200/1563]     || Average Training Loss: 3.0715\n",
      "Epoch: [19/50]         || Step: [1300/1563]     || Average Training Loss: 3.0741\n",
      "Epoch: [19/50]         || Step: [1400/1563]     || Average Training Loss: 3.0726\n",
      "Epoch: [19/50]         || Step: [1500/1563]     || Average Training Loss: 3.0713\n",
      "Epoch: [19/50]         || Step: [0/188]         || Average Validation Loss: 3.2168\n",
      "Epoch: [19/50]         || Step: [100/188]       || Average Validation Loss: 3.0318\n",
      "****************************************************************************************************\n",
      "Epoch: [19/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 353.335863\n",
      "****************************************************************************************************\n",
      "Epoch: [20/50]         || Step: [0/1563]        || Average Training Loss: 2.9507\n",
      "Epoch: [20/50]         || Step: [100/1563]      || Average Training Loss: 3.0737\n",
      "Epoch: [20/50]         || Step: [200/1563]      || Average Training Loss: 3.0675\n",
      "Epoch: [20/50]         || Step: [300/1563]      || Average Training Loss: 3.0670\n",
      "Epoch: [20/50]         || Step: [400/1563]      || Average Training Loss: 3.0669\n",
      "Epoch: [20/50]         || Step: [500/1563]      || Average Training Loss: 3.0677\n",
      "Epoch: [20/50]         || Step: [600/1563]      || Average Training Loss: 3.0649\n",
      "Epoch: [20/50]         || Step: [700/1563]      || Average Training Loss: 3.0659\n",
      "Epoch: [20/50]         || Step: [800/1563]      || Average Training Loss: 3.0680\n",
      "Epoch: [20/50]         || Step: [900/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [20/50]         || Step: [1000/1563]     || Average Training Loss: 3.0692\n",
      "Epoch: [20/50]         || Step: [1100/1563]     || Average Training Loss: 3.0696\n",
      "Epoch: [20/50]         || Step: [1200/1563]     || Average Training Loss: 3.0723\n",
      "Epoch: [20/50]         || Step: [1300/1563]     || Average Training Loss: 3.0714\n",
      "Epoch: [20/50]         || Step: [1400/1563]     || Average Training Loss: 3.0723\n",
      "Epoch: [20/50]         || Step: [1500/1563]     || Average Training Loss: 3.0712\n",
      "Epoch: [20/50]         || Step: [0/188]         || Average Validation Loss: 2.8963\n",
      "Epoch: [20/50]         || Step: [100/188]       || Average Validation Loss: 3.0114\n",
      "****************************************************************************************************\n",
      "Epoch: [20/50] || Training Loss = 3.07 || Validation Loss: 3.02 || Time: 370.842258\n",
      "****************************************************************************************************\n",
      "Epoch: [21/50]         || Step: [0/1563]        || Average Training Loss: 3.0961\n",
      "Epoch: [21/50]         || Step: [100/1563]      || Average Training Loss: 3.0452\n",
      "Epoch: [21/50]         || Step: [200/1563]      || Average Training Loss: 3.0500\n",
      "Epoch: [21/50]         || Step: [300/1563]      || Average Training Loss: 3.0475\n",
      "Epoch: [21/50]         || Step: [400/1563]      || Average Training Loss: 3.0625\n",
      "Epoch: [21/50]         || Step: [500/1563]      || Average Training Loss: 3.0635\n",
      "Epoch: [21/50]         || Step: [600/1563]      || Average Training Loss: 3.0618\n",
      "Epoch: [21/50]         || Step: [700/1563]      || Average Training Loss: 3.0641\n",
      "Epoch: [21/50]         || Step: [800/1563]      || Average Training Loss: 3.0640\n",
      "Epoch: [21/50]         || Step: [900/1563]      || Average Training Loss: 3.0668\n",
      "Epoch: [21/50]         || Step: [1000/1563]     || Average Training Loss: 3.0672\n",
      "Epoch: [21/50]         || Step: [1100/1563]     || Average Training Loss: 3.0661\n",
      "Epoch: [21/50]         || Step: [1200/1563]     || Average Training Loss: 3.0674\n",
      "Epoch: [21/50]         || Step: [1300/1563]     || Average Training Loss: 3.0669\n",
      "Epoch: [21/50]         || Step: [1400/1563]     || Average Training Loss: 3.0680\n",
      "Epoch: [21/50]         || Step: [1500/1563]     || Average Training Loss: 3.0692\n",
      "Epoch: [21/50]         || Step: [0/188]         || Average Validation Loss: 3.3432\n",
      "Epoch: [21/50]         || Step: [100/188]       || Average Validation Loss: 3.0507\n",
      "****************************************************************************************************\n",
      "Epoch: [21/50] || Training Loss = 3.07 || Validation Loss: 3.05 || Time: 388.389268\n",
      "****************************************************************************************************\n",
      "Epoch: [22/50]         || Step: [0/1563]        || Average Training Loss: 3.0101\n",
      "Epoch: [22/50]         || Step: [100/1563]      || Average Training Loss: 3.0397\n",
      "Epoch: [22/50]         || Step: [200/1563]      || Average Training Loss: 3.0553\n",
      "Epoch: [22/50]         || Step: [300/1563]      || Average Training Loss: 3.0647\n",
      "Epoch: [22/50]         || Step: [400/1563]      || Average Training Loss: 3.0604\n",
      "Epoch: [22/50]         || Step: [500/1563]      || Average Training Loss: 3.0664\n",
      "Epoch: [22/50]         || Step: [600/1563]      || Average Training Loss: 3.0658\n",
      "Epoch: [22/50]         || Step: [700/1563]      || Average Training Loss: 3.0603\n",
      "Epoch: [22/50]         || Step: [800/1563]      || Average Training Loss: 3.0618\n",
      "Epoch: [22/50]         || Step: [900/1563]      || Average Training Loss: 3.0623\n",
      "Epoch: [22/50]         || Step: [1000/1563]     || Average Training Loss: 3.0629\n",
      "Epoch: [22/50]         || Step: [1100/1563]     || Average Training Loss: 3.0645\n",
      "Epoch: [22/50]         || Step: [1200/1563]     || Average Training Loss: 3.0659\n",
      "Epoch: [22/50]         || Step: [1300/1563]     || Average Training Loss: 3.0658\n",
      "Epoch: [22/50]         || Step: [1400/1563]     || Average Training Loss: 3.0656\n",
      "Epoch: [22/50]         || Step: [1500/1563]     || Average Training Loss: 3.0681\n",
      "Epoch: [22/50]         || Step: [0/188]         || Average Validation Loss: 2.9474\n",
      "Epoch: [22/50]         || Step: [100/188]       || Average Validation Loss: 3.0256\n",
      "****************************************************************************************************\n",
      "Epoch: [22/50] || Training Loss = 3.07 || Validation Loss: 3.02 || Time: 405.765568\n",
      "****************************************************************************************************\n",
      "Epoch: [23/50]         || Step: [0/1563]        || Average Training Loss: 2.7777\n",
      "Epoch: [23/50]         || Step: [100/1563]      || Average Training Loss: 3.0756\n",
      "Epoch: [23/50]         || Step: [200/1563]      || Average Training Loss: 3.0782\n",
      "Epoch: [23/50]         || Step: [300/1563]      || Average Training Loss: 3.0744\n",
      "Epoch: [23/50]         || Step: [400/1563]      || Average Training Loss: 3.0728\n",
      "Epoch: [23/50]         || Step: [500/1563]      || Average Training Loss: 3.0716\n",
      "Epoch: [23/50]         || Step: [600/1563]      || Average Training Loss: 3.0724\n",
      "Epoch: [23/50]         || Step: [700/1563]      || Average Training Loss: 3.0725\n",
      "Epoch: [23/50]         || Step: [800/1563]      || Average Training Loss: 3.0730\n",
      "Epoch: [23/50]         || Step: [900/1563]      || Average Training Loss: 3.0755\n",
      "Epoch: [23/50]         || Step: [1000/1563]     || Average Training Loss: 3.0715\n",
      "Epoch: [23/50]         || Step: [1100/1563]     || Average Training Loss: 3.0729\n",
      "Epoch: [23/50]         || Step: [1200/1563]     || Average Training Loss: 3.0725\n",
      "Epoch: [23/50]         || Step: [1300/1563]     || Average Training Loss: 3.0709\n",
      "Epoch: [23/50]         || Step: [1400/1563]     || Average Training Loss: 3.0710\n",
      "Epoch: [23/50]         || Step: [1500/1563]     || Average Training Loss: 3.0689\n",
      "Epoch: [23/50]         || Step: [0/188]         || Average Validation Loss: 3.0878\n",
      "Epoch: [23/50]         || Step: [100/188]       || Average Validation Loss: 3.0227\n",
      "****************************************************************************************************\n",
      "Epoch: [23/50] || Training Loss = 3.07 || Validation Loss: 3.02 || Time: 422.222986\n",
      "****************************************************************************************************\n",
      "Epoch: [24/50]         || Step: [0/1563]        || Average Training Loss: 3.0178\n",
      "Epoch: [24/50]         || Step: [100/1563]      || Average Training Loss: 3.0347\n",
      "Epoch: [24/50]         || Step: [200/1563]      || Average Training Loss: 3.0491\n",
      "Epoch: [24/50]         || Step: [300/1563]      || Average Training Loss: 3.0539\n",
      "Epoch: [24/50]         || Step: [400/1563]      || Average Training Loss: 3.0590\n",
      "Epoch: [24/50]         || Step: [500/1563]      || Average Training Loss: 3.0564\n",
      "Epoch: [24/50]         || Step: [600/1563]      || Average Training Loss: 3.0621\n",
      "Epoch: [24/50]         || Step: [700/1563]      || Average Training Loss: 3.0630\n",
      "Epoch: [24/50]         || Step: [800/1563]      || Average Training Loss: 3.0665\n",
      "Epoch: [24/50]         || Step: [900/1563]      || Average Training Loss: 3.0657\n",
      "Epoch: [24/50]         || Step: [1000/1563]     || Average Training Loss: 3.0688\n",
      "Epoch: [24/50]         || Step: [1100/1563]     || Average Training Loss: 3.0668\n",
      "Epoch: [24/50]         || Step: [1200/1563]     || Average Training Loss: 3.0687\n",
      "Epoch: [24/50]         || Step: [1300/1563]     || Average Training Loss: 3.0698\n",
      "Epoch: [24/50]         || Step: [1400/1563]     || Average Training Loss: 3.0693\n",
      "Epoch: [24/50]         || Step: [1500/1563]     || Average Training Loss: 3.0695\n",
      "Epoch: [24/50]         || Step: [0/188]         || Average Validation Loss: 3.0970\n",
      "Epoch: [24/50]         || Step: [100/188]       || Average Validation Loss: 3.0196\n",
      "****************************************************************************************************\n",
      "Epoch: [24/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 438.734902\n",
      "****************************************************************************************************\n",
      "Epoch: [25/50]         || Step: [0/1563]        || Average Training Loss: 3.1051\n",
      "Epoch: [25/50]         || Step: [100/1563]      || Average Training Loss: 3.0447\n",
      "Epoch: [25/50]         || Step: [200/1563]      || Average Training Loss: 3.0618\n",
      "Epoch: [25/50]         || Step: [300/1563]      || Average Training Loss: 3.0718\n",
      "Epoch: [25/50]         || Step: [400/1563]      || Average Training Loss: 3.0705\n",
      "Epoch: [25/50]         || Step: [500/1563]      || Average Training Loss: 3.0673\n",
      "Epoch: [25/50]         || Step: [600/1563]      || Average Training Loss: 3.0672\n",
      "Epoch: [25/50]         || Step: [700/1563]      || Average Training Loss: 3.0650\n",
      "Epoch: [25/50]         || Step: [800/1563]      || Average Training Loss: 3.0689\n",
      "Epoch: [25/50]         || Step: [900/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [25/50]         || Step: [1000/1563]     || Average Training Loss: 3.0695\n",
      "Epoch: [25/50]         || Step: [1100/1563]     || Average Training Loss: 3.0716\n",
      "Epoch: [25/50]         || Step: [1200/1563]     || Average Training Loss: 3.0698\n",
      "Epoch: [25/50]         || Step: [1300/1563]     || Average Training Loss: 3.0700\n",
      "Epoch: [25/50]         || Step: [1400/1563]     || Average Training Loss: 3.0706\n",
      "Epoch: [25/50]         || Step: [1500/1563]     || Average Training Loss: 3.0714\n",
      "Epoch: [25/50]         || Step: [0/188]         || Average Validation Loss: 3.1153\n",
      "Epoch: [25/50]         || Step: [100/188]       || Average Validation Loss: 3.0205\n",
      "****************************************************************************************************\n",
      "Epoch: [25/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 455.631621\n",
      "****************************************************************************************************\n",
      "Epoch: [26/50]         || Step: [0/1563]        || Average Training Loss: 3.2065\n",
      "Epoch: [26/50]         || Step: [100/1563]      || Average Training Loss: 3.0638\n",
      "Epoch: [26/50]         || Step: [200/1563]      || Average Training Loss: 3.0485\n",
      "Epoch: [26/50]         || Step: [300/1563]      || Average Training Loss: 3.0580\n",
      "Epoch: [26/50]         || Step: [400/1563]      || Average Training Loss: 3.0634\n",
      "Epoch: [26/50]         || Step: [500/1563]      || Average Training Loss: 3.0664\n",
      "Epoch: [26/50]         || Step: [600/1563]      || Average Training Loss: 3.0671\n",
      "Epoch: [26/50]         || Step: [700/1563]      || Average Training Loss: 3.0675\n",
      "Epoch: [26/50]         || Step: [800/1563]      || Average Training Loss: 3.0678\n",
      "Epoch: [26/50]         || Step: [900/1563]      || Average Training Loss: 3.0679\n",
      "Epoch: [26/50]         || Step: [1000/1563]     || Average Training Loss: 3.0646\n",
      "Epoch: [26/50]         || Step: [1100/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [26/50]         || Step: [1200/1563]     || Average Training Loss: 3.0665\n",
      "Epoch: [26/50]         || Step: [1300/1563]     || Average Training Loss: 3.0673\n",
      "Epoch: [26/50]         || Step: [1400/1563]     || Average Training Loss: 3.0666\n",
      "Epoch: [26/50]         || Step: [1500/1563]     || Average Training Loss: 3.0653\n",
      "Epoch: [26/50]         || Step: [0/188]         || Average Validation Loss: 3.1095\n",
      "Epoch: [26/50]         || Step: [100/188]       || Average Validation Loss: 3.0324\n",
      "****************************************************************************************************\n",
      "Epoch: [26/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 473.308430\n",
      "****************************************************************************************************\n",
      "Epoch: [27/50]         || Step: [0/1563]        || Average Training Loss: 3.0062\n",
      "Epoch: [27/50]         || Step: [100/1563]      || Average Training Loss: 3.0607\n",
      "Epoch: [27/50]         || Step: [200/1563]      || Average Training Loss: 3.0583\n",
      "Epoch: [27/50]         || Step: [300/1563]      || Average Training Loss: 3.0585\n",
      "Epoch: [27/50]         || Step: [400/1563]      || Average Training Loss: 3.0594\n",
      "Epoch: [27/50]         || Step: [500/1563]      || Average Training Loss: 3.0593\n",
      "Epoch: [27/50]         || Step: [600/1563]      || Average Training Loss: 3.0631\n",
      "Epoch: [27/50]         || Step: [700/1563]      || Average Training Loss: 3.0626\n",
      "Epoch: [27/50]         || Step: [800/1563]      || Average Training Loss: 3.0625\n",
      "Epoch: [27/50]         || Step: [900/1563]      || Average Training Loss: 3.0595\n",
      "Epoch: [27/50]         || Step: [1000/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [27/50]         || Step: [1100/1563]     || Average Training Loss: 3.0637\n",
      "Epoch: [27/50]         || Step: [1200/1563]     || Average Training Loss: 3.0640\n",
      "Epoch: [27/50]         || Step: [1300/1563]     || Average Training Loss: 3.0654\n",
      "Epoch: [27/50]         || Step: [1400/1563]     || Average Training Loss: 3.0669\n",
      "Epoch: [27/50]         || Step: [1500/1563]     || Average Training Loss: 3.0664\n",
      "Epoch: [27/50]         || Step: [0/188]         || Average Validation Loss: 3.1006\n",
      "Epoch: [27/50]         || Step: [100/188]       || Average Validation Loss: 3.0298\n",
      "****************************************************************************************************\n",
      "Epoch: [27/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 490.741705\n",
      "****************************************************************************************************\n",
      "Epoch: [28/50]         || Step: [0/1563]        || Average Training Loss: 3.0457\n",
      "Epoch: [28/50]         || Step: [100/1563]      || Average Training Loss: 3.0616\n",
      "Epoch: [28/50]         || Step: [200/1563]      || Average Training Loss: 3.0631\n",
      "Epoch: [28/50]         || Step: [300/1563]      || Average Training Loss: 3.0540\n",
      "Epoch: [28/50]         || Step: [400/1563]      || Average Training Loss: 3.0611\n",
      "Epoch: [28/50]         || Step: [500/1563]      || Average Training Loss: 3.0586\n",
      "Epoch: [28/50]         || Step: [600/1563]      || Average Training Loss: 3.0599\n",
      "Epoch: [28/50]         || Step: [700/1563]      || Average Training Loss: 3.0601\n",
      "Epoch: [28/50]         || Step: [800/1563]      || Average Training Loss: 3.0582\n",
      "Epoch: [28/50]         || Step: [900/1563]      || Average Training Loss: 3.0617\n",
      "Epoch: [28/50]         || Step: [1000/1563]     || Average Training Loss: 3.0645\n",
      "Epoch: [28/50]         || Step: [1100/1563]     || Average Training Loss: 3.0666\n",
      "Epoch: [28/50]         || Step: [1200/1563]     || Average Training Loss: 3.0671\n",
      "Epoch: [28/50]         || Step: [1300/1563]     || Average Training Loss: 3.0663\n",
      "Epoch: [28/50]         || Step: [1400/1563]     || Average Training Loss: 3.0652\n",
      "Epoch: [28/50]         || Step: [1500/1563]     || Average Training Loss: 3.0676\n",
      "Epoch: [28/50]         || Step: [0/188]         || Average Validation Loss: 3.2097\n",
      "Epoch: [28/50]         || Step: [100/188]       || Average Validation Loss: 3.0491\n",
      "****************************************************************************************************\n",
      "Epoch: [28/50] || Training Loss = 3.07 || Validation Loss: 3.03 || Time: 508.280460\n",
      "****************************************************************************************************\n",
      "Epoch: [29/50]         || Step: [0/1563]        || Average Training Loss: 2.7734\n",
      "Epoch: [29/50]         || Step: [100/1563]      || Average Training Loss: 3.0489\n",
      "Epoch: [29/50]         || Step: [200/1563]      || Average Training Loss: 3.0372\n",
      "Epoch: [29/50]         || Step: [300/1563]      || Average Training Loss: 3.0480\n",
      "Epoch: [29/50]         || Step: [400/1563]      || Average Training Loss: 3.0563\n",
      "Epoch: [29/50]         || Step: [500/1563]      || Average Training Loss: 3.0607\n",
      "Epoch: [29/50]         || Step: [600/1563]      || Average Training Loss: 3.0602\n",
      "Epoch: [29/50]         || Step: [700/1563]      || Average Training Loss: 3.0617\n",
      "Epoch: [29/50]         || Step: [800/1563]      || Average Training Loss: 3.0642\n",
      "Epoch: [29/50]         || Step: [900/1563]      || Average Training Loss: 3.0638\n",
      "Epoch: [29/50]         || Step: [1000/1563]     || Average Training Loss: 3.0611\n",
      "Epoch: [29/50]         || Step: [1100/1563]     || Average Training Loss: 3.0585\n",
      "Epoch: [29/50]         || Step: [1200/1563]     || Average Training Loss: 3.0604\n",
      "Epoch: [29/50]         || Step: [1300/1563]     || Average Training Loss: 3.0624\n",
      "Epoch: [29/50]         || Step: [1400/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [29/50]         || Step: [1500/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [29/50]         || Step: [0/188]         || Average Validation Loss: 3.1077\n",
      "Epoch: [29/50]         || Step: [100/188]       || Average Validation Loss: 3.0243\n",
      "****************************************************************************************************\n",
      "Epoch: [29/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 525.893087\n",
      "****************************************************************************************************\n",
      "Epoch: [30/50]         || Step: [0/1563]        || Average Training Loss: 2.8063\n",
      "Epoch: [30/50]         || Step: [100/1563]      || Average Training Loss: 3.0590\n",
      "Epoch: [30/50]         || Step: [200/1563]      || Average Training Loss: 3.0697\n",
      "Epoch: [30/50]         || Step: [300/1563]      || Average Training Loss: 3.0715\n",
      "Epoch: [30/50]         || Step: [400/1563]      || Average Training Loss: 3.0694\n",
      "Epoch: [30/50]         || Step: [500/1563]      || Average Training Loss: 3.0749\n",
      "Epoch: [30/50]         || Step: [600/1563]      || Average Training Loss: 3.0688\n",
      "Epoch: [30/50]         || Step: [700/1563]      || Average Training Loss: 3.0698\n",
      "Epoch: [30/50]         || Step: [800/1563]      || Average Training Loss: 3.0646\n",
      "Epoch: [30/50]         || Step: [900/1563]      || Average Training Loss: 3.0663\n",
      "Epoch: [30/50]         || Step: [1000/1563]     || Average Training Loss: 3.0670\n",
      "Epoch: [30/50]         || Step: [1100/1563]     || Average Training Loss: 3.0659\n",
      "Epoch: [30/50]         || Step: [1200/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [30/50]         || Step: [1300/1563]     || Average Training Loss: 3.0629\n",
      "Epoch: [30/50]         || Step: [1400/1563]     || Average Training Loss: 3.0642\n",
      "Epoch: [30/50]         || Step: [1500/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [30/50]         || Step: [0/188]         || Average Validation Loss: 2.9153\n",
      "Epoch: [30/50]         || Step: [100/188]       || Average Validation Loss: 3.0356\n",
      "****************************************************************************************************\n",
      "Epoch: [30/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 543.367249\n",
      "****************************************************************************************************\n",
      "Epoch: [31/50]         || Step: [0/1563]        || Average Training Loss: 2.8596\n",
      "Epoch: [31/50]         || Step: [100/1563]      || Average Training Loss: 3.1010\n",
      "Epoch: [31/50]         || Step: [200/1563]      || Average Training Loss: 3.0850\n",
      "Epoch: [31/50]         || Step: [300/1563]      || Average Training Loss: 3.0725\n",
      "Epoch: [31/50]         || Step: [400/1563]      || Average Training Loss: 3.0734\n",
      "Epoch: [31/50]         || Step: [500/1563]      || Average Training Loss: 3.0748\n",
      "Epoch: [31/50]         || Step: [600/1563]      || Average Training Loss: 3.0714\n",
      "Epoch: [31/50]         || Step: [700/1563]      || Average Training Loss: 3.0710\n",
      "Epoch: [31/50]         || Step: [800/1563]      || Average Training Loss: 3.0705\n",
      "Epoch: [31/50]         || Step: [900/1563]      || Average Training Loss: 3.0686\n",
      "Epoch: [31/50]         || Step: [1000/1563]     || Average Training Loss: 3.0655\n",
      "Epoch: [31/50]         || Step: [1100/1563]     || Average Training Loss: 3.0672\n",
      "Epoch: [31/50]         || Step: [1200/1563]     || Average Training Loss: 3.0662\n",
      "Epoch: [31/50]         || Step: [1300/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [31/50]         || Step: [1400/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [31/50]         || Step: [1500/1563]     || Average Training Loss: 3.0643\n",
      "Epoch: [31/50]         || Step: [0/188]         || Average Validation Loss: 2.7478\n",
      "Epoch: [31/50]         || Step: [100/188]       || Average Validation Loss: 3.0196\n",
      "****************************************************************************************************\n",
      "Epoch: [31/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 560.864544\n",
      "****************************************************************************************************\n",
      "Epoch: [32/50]         || Step: [0/1563]        || Average Training Loss: 3.3294\n",
      "Epoch: [32/50]         || Step: [100/1563]      || Average Training Loss: 3.0427\n",
      "Epoch: [32/50]         || Step: [200/1563]      || Average Training Loss: 3.0390\n",
      "Epoch: [32/50]         || Step: [300/1563]      || Average Training Loss: 3.0452\n",
      "Epoch: [32/50]         || Step: [400/1563]      || Average Training Loss: 3.0522\n",
      "Epoch: [32/50]         || Step: [500/1563]      || Average Training Loss: 3.0547\n",
      "Epoch: [32/50]         || Step: [600/1563]      || Average Training Loss: 3.0556\n",
      "Epoch: [32/50]         || Step: [700/1563]      || Average Training Loss: 3.0620\n",
      "Epoch: [32/50]         || Step: [800/1563]      || Average Training Loss: 3.0629\n",
      "Epoch: [32/50]         || Step: [900/1563]      || Average Training Loss: 3.0635\n",
      "Epoch: [32/50]         || Step: [1000/1563]     || Average Training Loss: 3.0650\n",
      "Epoch: [32/50]         || Step: [1100/1563]     || Average Training Loss: 3.0641\n",
      "Epoch: [32/50]         || Step: [1200/1563]     || Average Training Loss: 3.0645\n",
      "Epoch: [32/50]         || Step: [1300/1563]     || Average Training Loss: 3.0659\n",
      "Epoch: [32/50]         || Step: [1400/1563]     || Average Training Loss: 3.0644\n",
      "Epoch: [32/50]         || Step: [1500/1563]     || Average Training Loss: 3.0658\n",
      "Epoch: [32/50]         || Step: [0/188]         || Average Validation Loss: 2.8844\n",
      "Epoch: [32/50]         || Step: [100/188]       || Average Validation Loss: 3.0207\n",
      "****************************************************************************************************\n",
      "Epoch: [32/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 576.954279\n",
      "****************************************************************************************************\n",
      "Epoch: [33/50]         || Step: [0/1563]        || Average Training Loss: 2.7186\n",
      "Epoch: [33/50]         || Step: [100/1563]      || Average Training Loss: 3.0646\n",
      "Epoch: [33/50]         || Step: [200/1563]      || Average Training Loss: 3.0651\n",
      "Epoch: [33/50]         || Step: [300/1563]      || Average Training Loss: 3.0737\n",
      "Epoch: [33/50]         || Step: [400/1563]      || Average Training Loss: 3.0707\n",
      "Epoch: [33/50]         || Step: [500/1563]      || Average Training Loss: 3.0703\n",
      "Epoch: [33/50]         || Step: [600/1563]      || Average Training Loss: 3.0726\n",
      "Epoch: [33/50]         || Step: [700/1563]      || Average Training Loss: 3.0701\n",
      "Epoch: [33/50]         || Step: [800/1563]      || Average Training Loss: 3.0691\n",
      "Epoch: [33/50]         || Step: [900/1563]      || Average Training Loss: 3.0683\n",
      "Epoch: [33/50]         || Step: [1000/1563]     || Average Training Loss: 3.0675\n",
      "Epoch: [33/50]         || Step: [1100/1563]     || Average Training Loss: 3.0678\n",
      "Epoch: [33/50]         || Step: [1200/1563]     || Average Training Loss: 3.0671\n",
      "Epoch: [33/50]         || Step: [1300/1563]     || Average Training Loss: 3.0653\n",
      "Epoch: [33/50]         || Step: [1400/1563]     || Average Training Loss: 3.0643\n",
      "Epoch: [33/50]         || Step: [1500/1563]     || Average Training Loss: 3.0623\n",
      "Epoch: [33/50]         || Step: [0/188]         || Average Validation Loss: 3.2995\n",
      "Epoch: [33/50]         || Step: [100/188]       || Average Validation Loss: 3.0221\n",
      "****************************************************************************************************\n",
      "Epoch: [33/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 591.767603\n",
      "****************************************************************************************************\n",
      "Epoch: [34/50]         || Step: [0/1563]        || Average Training Loss: 2.8886\n",
      "Epoch: [34/50]         || Step: [100/1563]      || Average Training Loss: 3.0664\n",
      "Epoch: [34/50]         || Step: [200/1563]      || Average Training Loss: 3.0480\n",
      "Epoch: [34/50]         || Step: [300/1563]      || Average Training Loss: 3.0464\n",
      "Epoch: [34/50]         || Step: [400/1563]      || Average Training Loss: 3.0532\n",
      "Epoch: [34/50]         || Step: [500/1563]      || Average Training Loss: 3.0578\n",
      "Epoch: [34/50]         || Step: [600/1563]      || Average Training Loss: 3.0597\n",
      "Epoch: [34/50]         || Step: [700/1563]      || Average Training Loss: 3.0598\n",
      "Epoch: [34/50]         || Step: [800/1563]      || Average Training Loss: 3.0616\n",
      "Epoch: [34/50]         || Step: [900/1563]      || Average Training Loss: 3.0638\n",
      "Epoch: [34/50]         || Step: [1000/1563]     || Average Training Loss: 3.0647\n",
      "Epoch: [34/50]         || Step: [1100/1563]     || Average Training Loss: 3.0627\n",
      "Epoch: [34/50]         || Step: [1200/1563]     || Average Training Loss: 3.0622\n",
      "Epoch: [34/50]         || Step: [1300/1563]     || Average Training Loss: 3.0635\n",
      "Epoch: [34/50]         || Step: [1400/1563]     || Average Training Loss: 3.0632\n",
      "Epoch: [34/50]         || Step: [1500/1563]     || Average Training Loss: 3.0636\n",
      "Epoch: [34/50]         || Step: [0/188]         || Average Validation Loss: 3.0938\n",
      "Epoch: [34/50]         || Step: [100/188]       || Average Validation Loss: 2.9967\n",
      "****************************************************************************************************\n",
      "Epoch: [34/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 609.246629\n",
      "****************************************************************************************************\n",
      "Epoch: [35/50]         || Step: [0/1563]        || Average Training Loss: 3.1311\n",
      "Epoch: [35/50]         || Step: [100/1563]      || Average Training Loss: 3.0474\n",
      "Epoch: [35/50]         || Step: [200/1563]      || Average Training Loss: 3.0452\n",
      "Epoch: [35/50]         || Step: [300/1563]      || Average Training Loss: 3.0483\n",
      "Epoch: [35/50]         || Step: [400/1563]      || Average Training Loss: 3.0553\n",
      "Epoch: [35/50]         || Step: [500/1563]      || Average Training Loss: 3.0580\n",
      "Epoch: [35/50]         || Step: [600/1563]      || Average Training Loss: 3.0578\n",
      "Epoch: [35/50]         || Step: [700/1563]      || Average Training Loss: 3.0602\n",
      "Epoch: [35/50]         || Step: [800/1563]      || Average Training Loss: 3.0624\n",
      "Epoch: [35/50]         || Step: [900/1563]      || Average Training Loss: 3.0602\n",
      "Epoch: [35/50]         || Step: [1000/1563]     || Average Training Loss: 3.0605\n",
      "Epoch: [35/50]         || Step: [1100/1563]     || Average Training Loss: 3.0582\n",
      "Epoch: [35/50]         || Step: [1200/1563]     || Average Training Loss: 3.0616\n",
      "Epoch: [35/50]         || Step: [1300/1563]     || Average Training Loss: 3.0614\n",
      "Epoch: [35/50]         || Step: [1400/1563]     || Average Training Loss: 3.0639\n",
      "Epoch: [35/50]         || Step: [1500/1563]     || Average Training Loss: 3.0623\n",
      "Epoch: [35/50]         || Step: [0/188]         || Average Validation Loss: 3.0722\n",
      "Epoch: [35/50]         || Step: [100/188]       || Average Validation Loss: 3.0013\n",
      "****************************************************************************************************\n",
      "Epoch: [35/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 626.777331\n",
      "****************************************************************************************************\n",
      "Epoch: [36/50]         || Step: [0/1563]        || Average Training Loss: 2.9734\n",
      "Epoch: [36/50]         || Step: [100/1563]      || Average Training Loss: 3.0219\n",
      "Epoch: [36/50]         || Step: [200/1563]      || Average Training Loss: 3.0239\n",
      "Epoch: [36/50]         || Step: [300/1563]      || Average Training Loss: 3.0421\n",
      "Epoch: [36/50]         || Step: [400/1563]      || Average Training Loss: 3.0528\n",
      "Epoch: [36/50]         || Step: [500/1563]      || Average Training Loss: 3.0523\n",
      "Epoch: [36/50]         || Step: [600/1563]      || Average Training Loss: 3.0551\n",
      "Epoch: [36/50]         || Step: [700/1563]      || Average Training Loss: 3.0572\n",
      "Epoch: [36/50]         || Step: [800/1563]      || Average Training Loss: 3.0586\n",
      "Epoch: [36/50]         || Step: [900/1563]      || Average Training Loss: 3.0592\n",
      "Epoch: [36/50]         || Step: [1000/1563]     || Average Training Loss: 3.0615\n",
      "Epoch: [36/50]         || Step: [1100/1563]     || Average Training Loss: 3.0612\n",
      "Epoch: [36/50]         || Step: [1200/1563]     || Average Training Loss: 3.0629\n",
      "Epoch: [36/50]         || Step: [1300/1563]     || Average Training Loss: 3.0623\n",
      "Epoch: [36/50]         || Step: [1400/1563]     || Average Training Loss: 3.0634\n",
      "Epoch: [36/50]         || Step: [1500/1563]     || Average Training Loss: 3.0632\n",
      "Epoch: [36/50]         || Step: [0/188]         || Average Validation Loss: 2.9821\n",
      "Epoch: [36/50]         || Step: [100/188]       || Average Validation Loss: 3.0315\n",
      "****************************************************************************************************\n",
      "Epoch: [36/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 644.209783\n",
      "****************************************************************************************************\n",
      "Epoch: [37/50]         || Step: [0/1563]        || Average Training Loss: 2.9402\n",
      "Epoch: [37/50]         || Step: [100/1563]      || Average Training Loss: 3.0645\n",
      "Epoch: [37/50]         || Step: [200/1563]      || Average Training Loss: 3.0726\n",
      "Epoch: [37/50]         || Step: [300/1563]      || Average Training Loss: 3.0712\n",
      "Epoch: [37/50]         || Step: [400/1563]      || Average Training Loss: 3.0632\n",
      "Epoch: [37/50]         || Step: [500/1563]      || Average Training Loss: 3.0613\n",
      "Epoch: [37/50]         || Step: [600/1563]      || Average Training Loss: 3.0678\n",
      "Epoch: [37/50]         || Step: [700/1563]      || Average Training Loss: 3.0639\n",
      "Epoch: [37/50]         || Step: [800/1563]      || Average Training Loss: 3.0615\n",
      "Epoch: [37/50]         || Step: [900/1563]      || Average Training Loss: 3.0605\n",
      "Epoch: [37/50]         || Step: [1000/1563]     || Average Training Loss: 3.0612\n",
      "Epoch: [37/50]         || Step: [1100/1563]     || Average Training Loss: 3.0639\n",
      "Epoch: [37/50]         || Step: [1200/1563]     || Average Training Loss: 3.0639\n",
      "Epoch: [37/50]         || Step: [1300/1563]     || Average Training Loss: 3.0642\n",
      "Epoch: [37/50]         || Step: [1400/1563]     || Average Training Loss: 3.0635\n",
      "Epoch: [37/50]         || Step: [1500/1563]     || Average Training Loss: 3.0631\n",
      "Epoch: [37/50]         || Step: [0/188]         || Average Validation Loss: 3.1208\n",
      "Epoch: [37/50]         || Step: [100/188]       || Average Validation Loss: 3.0408\n",
      "****************************************************************************************************\n",
      "Epoch: [37/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 661.700067\n",
      "****************************************************************************************************\n",
      "Epoch: [38/50]         || Step: [0/1563]        || Average Training Loss: 3.1849\n",
      "Epoch: [38/50]         || Step: [100/1563]      || Average Training Loss: 3.0471\n",
      "Epoch: [38/50]         || Step: [200/1563]      || Average Training Loss: 3.0551\n",
      "Epoch: [38/50]         || Step: [300/1563]      || Average Training Loss: 3.0639\n",
      "Epoch: [38/50]         || Step: [400/1563]      || Average Training Loss: 3.0618\n",
      "Epoch: [38/50]         || Step: [500/1563]      || Average Training Loss: 3.0657\n",
      "Epoch: [38/50]         || Step: [600/1563]      || Average Training Loss: 3.0621\n",
      "Epoch: [38/50]         || Step: [700/1563]      || Average Training Loss: 3.0605\n",
      "Epoch: [38/50]         || Step: [800/1563]      || Average Training Loss: 3.0602\n",
      "Epoch: [38/50]         || Step: [900/1563]      || Average Training Loss: 3.0600\n",
      "Epoch: [38/50]         || Step: [1000/1563]     || Average Training Loss: 3.0609\n",
      "Epoch: [38/50]         || Step: [1100/1563]     || Average Training Loss: 3.0592\n",
      "Epoch: [38/50]         || Step: [1200/1563]     || Average Training Loss: 3.0581\n",
      "Epoch: [38/50]         || Step: [1300/1563]     || Average Training Loss: 3.0605\n",
      "Epoch: [38/50]         || Step: [1400/1563]     || Average Training Loss: 3.0618\n",
      "Epoch: [38/50]         || Step: [1500/1563]     || Average Training Loss: 3.0614\n",
      "Epoch: [38/50]         || Step: [0/188]         || Average Validation Loss: 3.1115\n",
      "Epoch: [38/50]         || Step: [100/188]       || Average Validation Loss: 3.0236\n",
      "****************************************************************************************************\n",
      "Epoch: [38/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 679.328021\n",
      "****************************************************************************************************\n",
      "Epoch: [39/50]         || Step: [0/1563]        || Average Training Loss: 3.0471\n",
      "Epoch: [39/50]         || Step: [100/1563]      || Average Training Loss: 3.0128\n",
      "Epoch: [39/50]         || Step: [200/1563]      || Average Training Loss: 3.0360\n",
      "Epoch: [39/50]         || Step: [300/1563]      || Average Training Loss: 3.0492\n",
      "Epoch: [39/50]         || Step: [400/1563]      || Average Training Loss: 3.0503\n",
      "Epoch: [39/50]         || Step: [500/1563]      || Average Training Loss: 3.0504\n",
      "Epoch: [39/50]         || Step: [600/1563]      || Average Training Loss: 3.0543\n",
      "Epoch: [39/50]         || Step: [700/1563]      || Average Training Loss: 3.0560\n",
      "Epoch: [39/50]         || Step: [800/1563]      || Average Training Loss: 3.0579\n",
      "Epoch: [39/50]         || Step: [900/1563]      || Average Training Loss: 3.0614\n",
      "Epoch: [39/50]         || Step: [1000/1563]     || Average Training Loss: 3.0640\n",
      "Epoch: [39/50]         || Step: [1100/1563]     || Average Training Loss: 3.0645\n",
      "Epoch: [39/50]         || Step: [1200/1563]     || Average Training Loss: 3.0645\n",
      "Epoch: [39/50]         || Step: [1300/1563]     || Average Training Loss: 3.0636\n",
      "Epoch: [39/50]         || Step: [1400/1563]     || Average Training Loss: 3.0643\n",
      "Epoch: [39/50]         || Step: [1500/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [39/50]         || Step: [0/188]         || Average Validation Loss: 3.4771\n",
      "Epoch: [39/50]         || Step: [100/188]       || Average Validation Loss: 3.0505\n",
      "****************************************************************************************************\n",
      "Epoch: [39/50] || Training Loss = 3.06 || Validation Loss: 3.05 || Time: 696.946913\n",
      "****************************************************************************************************\n",
      "Epoch: [40/50]         || Step: [0/1563]        || Average Training Loss: 2.7430\n",
      "Epoch: [40/50]         || Step: [100/1563]      || Average Training Loss: 3.0138\n",
      "Epoch: [40/50]         || Step: [200/1563]      || Average Training Loss: 3.0279\n",
      "Epoch: [40/50]         || Step: [300/1563]      || Average Training Loss: 3.0421\n",
      "Epoch: [40/50]         || Step: [400/1563]      || Average Training Loss: 3.0533\n",
      "Epoch: [40/50]         || Step: [500/1563]      || Average Training Loss: 3.0540\n",
      "Epoch: [40/50]         || Step: [600/1563]      || Average Training Loss: 3.0558\n",
      "Epoch: [40/50]         || Step: [700/1563]      || Average Training Loss: 3.0550\n",
      "Epoch: [40/50]         || Step: [800/1563]      || Average Training Loss: 3.0558\n",
      "Epoch: [40/50]         || Step: [900/1563]      || Average Training Loss: 3.0575\n",
      "Epoch: [40/50]         || Step: [1000/1563]     || Average Training Loss: 3.0569\n",
      "Epoch: [40/50]         || Step: [1100/1563]     || Average Training Loss: 3.0590\n",
      "Epoch: [40/50]         || Step: [1200/1563]     || Average Training Loss: 3.0601\n",
      "Epoch: [40/50]         || Step: [1300/1563]     || Average Training Loss: 3.0605\n",
      "Epoch: [40/50]         || Step: [1400/1563]     || Average Training Loss: 3.0614\n",
      "Epoch: [40/50]         || Step: [1500/1563]     || Average Training Loss: 3.0615\n",
      "Epoch: [40/50]         || Step: [0/188]         || Average Validation Loss: 3.0906\n",
      "Epoch: [40/50]         || Step: [100/188]       || Average Validation Loss: 3.0124\n",
      "****************************************************************************************************\n",
      "Epoch: [40/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 714.426396\n",
      "****************************************************************************************************\n",
      "Epoch: [41/50]         || Step: [0/1563]        || Average Training Loss: 3.0082\n",
      "Epoch: [41/50]         || Step: [100/1563]      || Average Training Loss: 3.0619\n",
      "Epoch: [41/50]         || Step: [200/1563]      || Average Training Loss: 3.0535\n",
      "Epoch: [41/50]         || Step: [300/1563]      || Average Training Loss: 3.0536\n",
      "Epoch: [41/50]         || Step: [400/1563]      || Average Training Loss: 3.0535\n",
      "Epoch: [41/50]         || Step: [500/1563]      || Average Training Loss: 3.0507\n",
      "Epoch: [41/50]         || Step: [600/1563]      || Average Training Loss: 3.0533\n",
      "Epoch: [41/50]         || Step: [700/1563]      || Average Training Loss: 3.0580\n",
      "Epoch: [41/50]         || Step: [800/1563]      || Average Training Loss: 3.0579\n",
      "Epoch: [41/50]         || Step: [900/1563]      || Average Training Loss: 3.0580\n",
      "Epoch: [41/50]         || Step: [1000/1563]     || Average Training Loss: 3.0587\n",
      "Epoch: [41/50]         || Step: [1100/1563]     || Average Training Loss: 3.0600\n",
      "Epoch: [41/50]         || Step: [1200/1563]     || Average Training Loss: 3.0605\n",
      "Epoch: [41/50]         || Step: [1300/1563]     || Average Training Loss: 3.0610\n",
      "Epoch: [41/50]         || Step: [1400/1563]     || Average Training Loss: 3.0613\n",
      "Epoch: [41/50]         || Step: [1500/1563]     || Average Training Loss: 3.0612\n",
      "Epoch: [41/50]         || Step: [0/188]         || Average Validation Loss: 3.0231\n",
      "Epoch: [41/50]         || Step: [100/188]       || Average Validation Loss: 3.0363\n",
      "****************************************************************************************************\n",
      "Epoch: [41/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 730.658709\n",
      "****************************************************************************************************\n",
      "Epoch: [42/50]         || Step: [0/1563]        || Average Training Loss: 2.7648\n",
      "Epoch: [42/50]         || Step: [100/1563]      || Average Training Loss: 3.0399\n",
      "Epoch: [42/50]         || Step: [200/1563]      || Average Training Loss: 3.0540\n",
      "Epoch: [42/50]         || Step: [300/1563]      || Average Training Loss: 3.0602\n",
      "Epoch: [42/50]         || Step: [400/1563]      || Average Training Loss: 3.0541\n",
      "Epoch: [42/50]         || Step: [500/1563]      || Average Training Loss: 3.0553\n",
      "Epoch: [42/50]         || Step: [600/1563]      || Average Training Loss: 3.0554\n",
      "Epoch: [42/50]         || Step: [700/1563]      || Average Training Loss: 3.0579\n",
      "Epoch: [42/50]         || Step: [800/1563]      || Average Training Loss: 3.0559\n",
      "Epoch: [42/50]         || Step: [900/1563]      || Average Training Loss: 3.0567\n",
      "Epoch: [42/50]         || Step: [1000/1563]     || Average Training Loss: 3.0591\n",
      "Epoch: [42/50]         || Step: [1100/1563]     || Average Training Loss: 3.0569\n",
      "Epoch: [42/50]         || Step: [1200/1563]     || Average Training Loss: 3.0604\n",
      "Epoch: [42/50]         || Step: [1300/1563]     || Average Training Loss: 3.0598\n",
      "Epoch: [42/50]         || Step: [1400/1563]     || Average Training Loss: 3.0616\n",
      "Epoch: [42/50]         || Step: [1500/1563]     || Average Training Loss: 3.0613\n",
      "Epoch: [42/50]         || Step: [0/188]         || Average Validation Loss: 3.1395\n",
      "Epoch: [42/50]         || Step: [100/188]       || Average Validation Loss: 3.0260\n",
      "****************************************************************************************************\n",
      "Epoch: [42/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 747.917296\n",
      "****************************************************************************************************\n",
      "Epoch: [43/50]         || Step: [0/1563]        || Average Training Loss: 2.7958\n",
      "Epoch: [43/50]         || Step: [100/1563]      || Average Training Loss: 3.0618\n",
      "Epoch: [43/50]         || Step: [200/1563]      || Average Training Loss: 3.0625\n",
      "Epoch: [43/50]         || Step: [300/1563]      || Average Training Loss: 3.0592\n",
      "Epoch: [43/50]         || Step: [400/1563]      || Average Training Loss: 3.0555\n",
      "Epoch: [43/50]         || Step: [500/1563]      || Average Training Loss: 3.0521\n",
      "Epoch: [43/50]         || Step: [600/1563]      || Average Training Loss: 3.0560\n",
      "Epoch: [43/50]         || Step: [700/1563]      || Average Training Loss: 3.0544\n",
      "Epoch: [43/50]         || Step: [800/1563]      || Average Training Loss: 3.0569\n",
      "Epoch: [43/50]         || Step: [900/1563]      || Average Training Loss: 3.0584\n",
      "Epoch: [43/50]         || Step: [1000/1563]     || Average Training Loss: 3.0596\n",
      "Epoch: [43/50]         || Step: [1100/1563]     || Average Training Loss: 3.0604\n",
      "Epoch: [43/50]         || Step: [1200/1563]     || Average Training Loss: 3.0626\n",
      "Epoch: [43/50]         || Step: [1300/1563]     || Average Training Loss: 3.0625\n",
      "Epoch: [43/50]         || Step: [1400/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [43/50]         || Step: [1500/1563]     || Average Training Loss: 3.0642\n",
      "Epoch: [43/50]         || Step: [0/188]         || Average Validation Loss: 2.9637\n",
      "Epoch: [43/50]         || Step: [100/188]       || Average Validation Loss: 3.0220\n",
      "****************************************************************************************************\n",
      "Epoch: [43/50] || Training Loss = 3.06 || Validation Loss: 3.03 || Time: 766.103196\n",
      "****************************************************************************************************\n",
      "Epoch: [44/50]         || Step: [0/1563]        || Average Training Loss: 3.0270\n",
      "Epoch: [44/50]         || Step: [100/1563]      || Average Training Loss: 3.0229\n",
      "Epoch: [44/50]         || Step: [200/1563]      || Average Training Loss: 3.0233\n",
      "Epoch: [44/50]         || Step: [300/1563]      || Average Training Loss: 3.0298\n",
      "Epoch: [44/50]         || Step: [400/1563]      || Average Training Loss: 3.0307\n",
      "Epoch: [44/50]         || Step: [500/1563]      || Average Training Loss: 3.0355\n",
      "Epoch: [44/50]         || Step: [600/1563]      || Average Training Loss: 3.0439\n",
      "Epoch: [44/50]         || Step: [700/1563]      || Average Training Loss: 3.0462\n",
      "Epoch: [44/50]         || Step: [800/1563]      || Average Training Loss: 3.0510\n",
      "Epoch: [44/50]         || Step: [900/1563]      || Average Training Loss: 3.0553\n",
      "Epoch: [44/50]         || Step: [1000/1563]     || Average Training Loss: 3.0570\n",
      "Epoch: [44/50]         || Step: [1100/1563]     || Average Training Loss: 3.0551\n",
      "Epoch: [44/50]         || Step: [1200/1563]     || Average Training Loss: 3.0573\n",
      "Epoch: [44/50]         || Step: [1300/1563]     || Average Training Loss: 3.0586\n",
      "Epoch: [44/50]         || Step: [1400/1563]     || Average Training Loss: 3.0590\n",
      "Epoch: [44/50]         || Step: [1500/1563]     || Average Training Loss: 3.0609\n",
      "Epoch: [44/50]         || Step: [0/188]         || Average Validation Loss: 3.0137\n",
      "Epoch: [44/50]         || Step: [100/188]       || Average Validation Loss: 3.0166\n",
      "****************************************************************************************************\n",
      "Epoch: [44/50] || Training Loss = 3.06 || Validation Loss: 3.02 || Time: 787.444530\n",
      "****************************************************************************************************\n",
      "Epoch: [45/50]         || Step: [0/1563]        || Average Training Loss: 3.0063\n",
      "Epoch: [45/50]         || Step: [100/1563]      || Average Training Loss: 3.0792\n",
      "Epoch: [45/50]         || Step: [200/1563]      || Average Training Loss: 3.0656\n",
      "Epoch: [45/50]         || Step: [300/1563]      || Average Training Loss: 3.0666\n",
      "Epoch: [45/50]         || Step: [400/1563]      || Average Training Loss: 3.0652\n",
      "Epoch: [45/50]         || Step: [500/1563]      || Average Training Loss: 3.0672\n",
      "Epoch: [45/50]         || Step: [600/1563]      || Average Training Loss: 3.0657\n",
      "Epoch: [45/50]         || Step: [700/1563]      || Average Training Loss: 3.0663\n",
      "Epoch: [45/50]         || Step: [800/1563]      || Average Training Loss: 3.0660\n",
      "Epoch: [45/50]         || Step: [900/1563]      || Average Training Loss: 3.0678\n",
      "Epoch: [45/50]         || Step: [1000/1563]     || Average Training Loss: 3.0667\n",
      "Epoch: [45/50]         || Step: [1100/1563]     || Average Training Loss: 3.0649\n",
      "Epoch: [45/50]         || Step: [1200/1563]     || Average Training Loss: 3.0643\n",
      "Epoch: [45/50]         || Step: [1300/1563]     || Average Training Loss: 3.0640\n",
      "Epoch: [45/50]         || Step: [1400/1563]     || Average Training Loss: 3.0639\n",
      "Epoch: [45/50]         || Step: [1500/1563]     || Average Training Loss: 3.0638\n",
      "Epoch: [45/50]         || Step: [0/188]         || Average Validation Loss: 3.0087\n",
      "Epoch: [45/50]         || Step: [100/188]       || Average Validation Loss: 3.0253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m: encoder,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m'\u001b[39m: decoder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m training_loss, validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Image Captioning/INM706-image-captioning/code/utils.py:119\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, criterion, optimizer, train_loader, val_loader, total_epoch, device, checkpoint_path, print_every, load_checkpoint)\u001b[0m\n\u001b[1;32m    116\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    117\u001b[0m decoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[1;32m    120\u001b[0m     idx, images, captions \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    121\u001b[0m     images, captions \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), captions\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Image Captioning/INM706-image-captioning/code/get_loader.py:179\u001b[0m, in \u001b[0;36mMSCOCODataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# get X: Image\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# get y: Image Caption\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_deque[idx][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Image Captioning/INM706-image-captioning/code/get_loader.py:150\u001b[0m, in \u001b[0;36mMSCOCODataset.load_img\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    148\u001b[0m img_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_deque[idx][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# convert the image to RGB to make sure all the images are 3D, because there are some images in grayscale\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_transforms(img)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/Image.py:889\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    252\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 253\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'encoder': encoder,\n",
    "    'decoder': decoder,\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'total_epoch': TOTAL_EPOCH,\n",
    "    'device': device,\n",
    "    'checkpoint_path': CHECKPOINT,\n",
    "    'print_every': PRINT_EVERY,\n",
    "    'load_checkpoint': False\n",
    "}\n",
    "\n",
    "training_loss, validation_loss = train(**train_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a44a5a-1769-4159-821f-dd82c9d7618e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
