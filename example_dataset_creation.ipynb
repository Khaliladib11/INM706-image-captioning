{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb6c834-819f-49f6-aae2-caea69ab812d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import Encoder, Decoder\n",
    "\n",
    "from pathlib import Path\n",
    "from DatasetInterface import MSCOCOInterface\n",
    "from utils import *\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "###### download the data we need\n",
    "# !cd ~/INM706-image-captioning/Datasets/coco/images/\n",
    "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
    "# !wget http://images.cocodataset.org/zips/val2017.zip\n",
    "# !unzip train2017.zip\n",
    "# !unzip val2017.zip\n",
    "# !rm train2017.zip\n",
    "# !rm val2017.zip\n",
    "\n",
    "##### run code below if nltk hasn't been set up in clound instance yet\n",
    "# !python -m nltk.downloader -d /usr/local/share/nltk_data all\n",
    "\n",
    "###### run code below to save pre-trained weights if needed\n",
    "# cd ~/INM706-image-captioning/model\n",
    "# !wget https://download.pytorch.org/models/resnet152-394f9c45.pth\n",
    "# !mv resnet152-394f9c45.pth resnet152_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1527336-dbeb-46a1-af50-b2c2cb192aff",
   "metadata": {},
   "source": [
    "## Load Dataset Interface and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72973a9-b35f-40dc-aff8-852dcd9bcb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 4000 images\n",
      " val dataset has 1000 images\n",
      " test dataset has 1000 images\n",
      "There are 25015 captions in the data set\n",
      "With FREQ_THRESHOLD = 2, vocab size is 4263\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# paths for Khalil\n",
    "#########\n",
    "# root = Path('Data')\n",
    "\n",
    "#captions_path = root/'annotations'/'captions_train2017.json'\n",
    "\n",
    "# train_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_train.json'\n",
    "# val_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_val.json'\n",
    "# test_captions_path = root/'annotations_trainval2017'/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "#########\n",
    "# paths for Alex\n",
    "#########\n",
    "\n",
    "root = Path('Datasets/coco')\n",
    "imgs_path = root/'images'/'train2017'\n",
    "imgs_path_test = root/'images'/'val2017'\n",
    "\n",
    "prepare_datasets(train_percent = 0.87, super_categories=None,\n",
    "                    max_train=4000, max_val=1000, max_test=1000)\n",
    "\n",
    "train_captions_path = root/'annotations'/'sports_captions_train.json'\n",
    "val_captions_path = root/'annotations'/'sports_captions_val.json'\n",
    "test_captions_path = root/'annotations'/'sports_captions_test.json'\n",
    "\n",
    "#### build vocab using full original coco train\n",
    "build_vocab(freq_threshold=2, sequence_length=40, captions_file=['sports_captions_train.json',\n",
    "                                                                 'sports_captions_val.json'])\n",
    "\n",
    "# load vocab\n",
    "with open('vocabulary/idx_to_string.json') as json_file:\n",
    "    idx_to_string_json = json.load(json_file)\n",
    "        \n",
    "idx_to_string = dict()\n",
    "for key in idx_to_string_json:\n",
    "    idx_to_string[int(key)] = idx_to_string_json[key]\n",
    "    \n",
    "with open('vocabulary/string_to_index.json') as json_file:\n",
    "    string_to_index = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982e8b8-146a-4542-882b-2e7a4ac6637f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
